[
["index.html", "Analysis of single-cell RNA-seq data 1 About the course 1.1 Registration 1.2 GitHub 1.3 License 1.4 Prerequisites 1.5 Contact", " Analysis of single-cell RNA-seq data Vladimir Kiselev, Tallulah Andrews and Martin Hemberg 2016-05-10   1 About the course Recent technological advances have made it possible to obtain genome-wide transcriptome data from single cells using high-throughput sequencing (scRNA-seq). The main advantage of scRNA-seq is that the cellular resolution and the genome wide scope makes it possible to address issues that are intractable using other methods, e.g. bulk RNA-seq or single-cell RT-qPCR. However, to analyze scRNA-seq data, novel methods are required and some of the underlying assumptions for the methods developed for bulk RNA-seq experiments are no longer valid. In this course we will be surveying the existing problems as well as the available computational and statistical frameworks available for the analysis of scRNA-seq. The course is taught through the University of Cambridge Bioinformatics training unit, but the material found on these pages is meant to be used for anyone interested in learning about computational analysis of scRNA-seq data.  1.1 Registration http://training.csx.cam.ac.uk/bioinformatics/event/1755391   1.2 GitHub https://github.com/hemberg-lab/scRNA.seq.course   1.3 License Creative Commons Attribution-NoDerivatives 4.0 International License   1.4 Prerequisites The course is intended for those who have basic familiarity with Unix and the R scripting language. We will also assume that you are familiar with mapping and analysing bulk RNA-seq data as well as with the commonly available computational tools. We recommend attending the Introduction to RNA-seq and ChIP-seq data analysis or the Analysis of high-throughput sequencing data with Bioconductor before attending this course.   1.5 Contact If you have any comments, questions or suggestions about the material, please contact Vladimir Kiselev.   "],
["technical-requirements.html", "2 Technical requirements", " 2 Technical requirements This course is based on the popular programming language R. However, one of the methods that we describe (SNN-Cliq) is only partly R-based. It makes a simple python call from R and requires a user to have write permissions to the current directory. You also need to download this file and put it in the ~/snn-cliq/ directory. Before running the course exercises, you also need to install the following R packages: devtools for installing packages from GitHub: install.packages(&quot;devtools&quot;) scRNA.seq.funcs - R package containing our functions used in this course: devtools::install_github(&quot;hemberg-lab/scRNA.seq.funcs&quot;) mvoutlier - for an automatic outlier detection in the scater package. install.packages(&quot;mvoutlier&quot;) M3D for identification of important and DE genes, developed by Tallulah Andrews: devtools::install_github(&quot;tallulandrews/M3D&quot;, ref = &quot;release&quot;) RUVSeq for normalization using ERCC controls: ## try http:// if https:// URLs are not supported source(&quot;https://bioconductor.org/biocLite.R&quot;) biocLite(&quot;RUVSeq&quot;) ROCR for performance estimations: install.packages(&quot;ROCR&quot;) limma for plotting Venn diagrams: ## try http:// if https:// URLs are not supported source(&quot;https://bioconductor.org/biocLite.R&quot;) biocLite(&quot;limma&quot;) DESeq2 for identification of differentially expressed genes: ## try http:// if https:// URLs are not supported source(&quot;https://bioconductor.org/biocLite.R&quot;) biocLite(&quot;DESeq2&quot;) scde for identification of differentially expressed genes: devtools::install_github(&quot;hms-dbmi/scde&quot;, build_vignettes = FALSE)  Installation on Mac OS X may require this additional gfortran library: curl -O http://r.research.att.com/libs/gfortran-4.8.2-darwin13.tar.bz2 sudo tar fvxz gfortran-4.8.2-darwin13.tar.bz2 -C / See the help page for additional support.  pheatmap for plotting heatmaps: install.packages(&quot;pheatmap&quot;) pcaMethods required by the pcaReduce package below for unsupervised clustering of scRNA-seq data: ## try http:// if https:// URLs are not supported source(&quot;https://bioconductor.org/biocLite.R&quot;) biocLite(&quot;pcaMethods&quot;) pcaReduce for unsupervised clustering of scRNA-seq data (bioRxiv): devtools::install_github(&quot;JustinaZ/pcaReduce&quot;) Rtsne for unsupervised clustering of scRNA-seq data: install.packages(&quot;Rtsne&quot;) SC3 for unsupervised clustering of scRNA-seq data (bioRxiv): devtools::install_github(&quot;hemberg-lab/SC3&quot;, ref = &quot;R-old&quot;)  Before running SC3 for the first time only, please start R and enter:  RSelenium::checkForServer()  "],
["introduction-to-single-cell-rna-seq.html", "3 Introduction to single-cell RNA-seq 3.1 Bulk RNA-seq 3.2 scRNA-seq 3.3 Protocol 3.4 Computational Analysis 3.5 Challenges 3.6 Controls", " 3 Introduction to single-cell RNA-seq  3.1 Bulk RNA-seq  A major breakthrough (replaced microarrays) in the late 00’s and has been widely used since Measures the average expression level for each gene across a large population of input cells Useful for comparative transcriptomics, e.g. samples of the same tissue from different species Useful for quantifying expression signatures from ensembles, e.g. in disease studies Insufficient for studying heterogeneous systems, e.g. early development studies, complex tissues (brain) Does not provide insights into the stochastic nature of gene expression    3.2 scRNA-seq  A new technology, first publication by (Tang et al. 2009) Measures the distribution of expression levels for each gene across a population of cells Allows to study new biological questions in which cell-specific changes in transcriptome are important, e.g. cell type identification, heterogeneity of cell responses, stochasticity of gene expression, inference of gene regulatory networks across the cells. Datasets range from \\(10^2\\) to \\(10^4\\) cells and increase in size every year Currently there are several different protocols in use, e.g. SMART-seq2 (Picelli et al. 2013), CELL-seq (Hashimshony et al. 2012) and Drop-seq (Macosko et al. 2015) Several computational analysis methods from bulk RNA-seq can be used In most cases computational analysis requires adaptation of the existing methods or development of new ones    3.3 Protocol    Figure 3.1: Single cell sequencing (taken from here)   Overall, experimental scRNA-seq protocols are similar to the methods used for bulk RNA-seq. For a discussion on experimental methods, please see reviews by (Saliba et al. 2014), (Handley et al. 2015) or (Kolodziejczyk et al. 2015).   3.4 Computational Analysis This course is concerned with the computational analysis of the data obtained from scRNA-seq experiments. The first steps (yellow) are general for any highthroughput sequencing data. Later steps (orange) require a mix of existing RNASeq analysis methods and novel methods to address the technical difference of scRNASeq. Finally the biological interpretation should be analyzed with methods specifically developed for scRNASeq.    Figure 3.2: Flowchart of the scRNA-seq analysis   There are several reviews of the scRNA-seq analysis available including (Stegle, Teichmann, and Marioni 2015).   3.5 Challenges The main difference between bulk and single cell RNA-seq is that each sequencing library represents a single cell, instead of a population of cells. Therefore, significant attention has to be paid to comparison of the results from different cells (sequencing libraries). The main sources of discrepancy between the libraries are:  Amplification (up to 1 million fold) Gene ‘dropouts’ in which a gene is observed at a moderate expression level in one cell but is not detected in another cell (Kharchenko, Silberstein, and Scadden 2014).  In both cases the discrepancies are introduced due to low starting amounts of transcripts since the RNA comes from one cell only. Improving the transcript capture efficiency and reducing the amplification bias are currently active areas of research.   3.6 Controls To provide better estimates of the technical variation between scRNA sequencing libraries two quantitative standards are frequently used. The aim of using spike-ins and UMIs is to facilitate normalization of gene expression levels across different cells.  3.6.1 Spike-ins Spike-ins are extrinsic RNA molecules of known concentration which are added to the lysate of each cell prior to the reverse transcription reaction. The most popular and widely used spike-ins are synthetic spikes from the External RNA Control Consortium (ERCC). This set of 96 synthetic mRNAs of differing length and GC content based on bacterial sequences (Jiang et al. 2011).   3.6.2 UMIs Another method of standardisation is to use Unique Molecular Identifiers (UMIs) (Kivioja et al. 2012). These are 4-20 bp barcode sequences which are added to the 3’ or 5’ end of each transcript prior to amplification (typically during reverse transcription). This is usually followed by targetted sequencing of the respective end of the transcripts. The barcodes make it possible to quantify the number of transcripts prior to the amplification step.    "],
["construction-of-expression-matrix.html", "4 Construction of expression matrix 4.1 Reads QC 4.2 Reads alignment 4.3 Alignment example 4.4 Mapping QC 4.5 Reads quantification", " 4 Construction of expression matrix  4.1 Reads QC The output from a scRNA-seq experiment is a large collection of cDNA reads. The first step is to ensure that the reads are of high quality. The quality control can be performed by using standard tools, such as FastQC or Kraken. Assuming that our reads are in experiment.bam, we run FastQC as $&lt;path_to_fastQC&gt;/fastQC experiment.bam Below is an example of the output from FastQC for a dataset of 125 bp reads. The plot reveals a technical error which resulted in a couple bases failing to be read correctly in the centre of the read. However, since the rest of the read was of high quality this error will most likely have a negligible effect on mapping efficiency.    Figure 4.1: Example of FastQC output   Additionally, it is often helpful to visualize the data using the Integrative Genomics Browser (IGV) or SeqMonk.   4.2 Reads alignment After trimming low quality bases from the reads, the remaining sequences can be mapped to a reference genome. Again, there is no need for a special purpose method for this, so we can use the STAR or the TopHat aligner. An example of how to map reads.bam to using STAR is $&lt;path_to_STAR&gt;/STAR --runThreadN 1 --runMode alignReads --readFilesIn reads1.fq.gz reads2.fq.gz --readFilesCommand zcat --genomeDir &lt;path&gt; --parametersFiles FileOfMoreParameters.txt --outFileNamePrefix &lt;outpath&gt;/output Note, if the spike-ins are used, the reference sequence should be augmented with the DNA sequence of the spike-in molecules prior to mapping. Note, when UMIs are used, their barcodes should be removed from the read sequence. A common practice is to add the barcode to the read name. Once the reads for each cell have been mapped to the reference genome, we need to make sure that a sufficient number of reads from each cell could be mapped to the reference genome. In our experience, the fraction of mappable reads for mouse or human cells is 60-70%. However, this result may vary depending on protocol, read length and settings for the read alignment. As a general rule, we expect all cells to have a similar fraction of mapped reads, so any outliers should be inspected and possibly removed. A low proportion of mappable reads usually indicates contamination.   4.3 Alignment example The histogram below shows the total number of reads mapped to each cell for an scRNA-seq experiment. Each bar represents one cell, and they have been sorted in ascending order by the total number of reads per cell. The three red arrows indicate cells that are outliers in terms of their coverage and they should be removed from further analysis. The two yellow arrows point to cells with a surprisingly large number of unmapped reads. In this example we kept the cells during the alignment QC step, but they were later removed during cell QC due to a high proportion of ribosomal RNA reads.    Figure 4.2: Example of the total number of reads mapped to each cell.     4.4 Mapping QC After mapping the raw sequencing to the genome we need to evaluate the quality of the mapping. There are many ways to measure the mapping quality, including: amount of reads mapping to rRNA/tRNAs, proportion of uniquely mapping reads, reads mapping across splice junctions, read depth along the transcripts. Methods developed for bulk RNA-seq, such as RSeQC, are applicable to single-cell data: python &lt;RSeQCpath&gt;/geneBody_coverage.py -i input.bam -r genome.bed -o output.txt python &lt;RSeQCpath&gt;/bam_stat.py -i input.bam -r genome.bed -o output.txt python &lt;RSeQCpath&gt;/split_bam.py -i input.bam -r rRNAmask.bed -o output.txt However the expected results will depend on the experimental protocol, e.g. many scRNA-seq methods use poly-A selection to avoid sequencing rRNAs which results in a 3’ bias in the read coverage across the genes (aka gene body coverage). The figure below shows this 3’ bias as well as three cells which were outliers and removed from the dataset:    Figure 4.3: Example of the 3’ bias in the read coverage.     4.5 Reads quantification The next step is to quantify the expression level of each gene for each cell. For mRNA data, we can use one of the tools which has been developed for bulk RNA-seq data, e.g. HT-seq or FeatureCounts # include multimapping &lt;featureCounts_path&gt;/featureCounts -O -M -Q 30 -p -a genome.gtf -o outputfile input.bam # exclude multimapping &lt;featureCounts_path&gt;/featureCounts -Q 30 -p -a genome.gtf -o outputfile input.bam  4.5.1 UMI quantification The number of unique barcodes used as UMIs is typically much smaller than the total number of mRNAs in a cell. Thus to properly count UMIs they must be separated into groups based on their mapping position. Most scRNASeq methods perform several rounds of PCR prior to fragmenting transcripts. As a result UMIs originating from the same mRNA won’t map to exactly the same position in the genome. Thus UMIs should be grouped by transcript or gene. One way to achieve this is to map reads to the transcriptome rather than the genome. Once UMIs have been grouped the number of original mRNA molecules can be estimated by counting the number of unique UMIs in each group. However, single base-pair substitutions introduced by errors during PCR or sequencing can create “new” unique UMIs inflating the counts. This effect depends on the length of the barcode used, longer = more potential errors. For instance using a 10bp barcode will result in ~7% of reads containing at least one error. To our knowledge the only software which attempts to correct for these errors is UMI-tools. They provide several different methods to quantify UMIs based on different assumptions about what type of errors occur in the barcodes (they discuss them in detail here).    "],
["scater-package.html", "5 scater package 5.1 Introduction 5.2 scater workflow 5.3 Terminology 5.4 SCESet class", " 5 scater package  5.1 Introduction scater is a R package single-cell RNA-seq analysis. The package contains several useful methods for quality control, visualisation and pre-processing of data prior to further downstream analysis. scater features the following functionality:  Automated computation of QC metrics Transcript quantification from read data with pseudo-alignment Data format standardisation Rich visualizations for exploratory analysis Seamless integration into the Bioconductor universe Simple normalisation methods  We highly recommend to use scater for all single-cell RNA-seq analyses and scater is the basis of the first part of the course.   5.2 scater workflow       5.3 Terminology (this chapter is taken from the scater vignette)  The capabilities of scater are built on top of Bioconductor’s Biobase. In Bioconductor terminology we assay numerous “features” for a number of “samples”. Features, in the context of scater, correspond most commonly to genes or transcripts, but could be any general genomic or transcriptomic regions (e.g. exon) of interest for which we take measurements. In the following chapters it may be more intuitive to mentally replace “feature” with “gene” or “transcript” (depending on the context of the study) wherever “feature” appears. In the scater context, “samples” refer to individual cells that we have assayed.    5.4 SCESet class (this chapter is taken from the scater vignette) In scater we organise single-cell expression data in objects of the SCESet class. The class inherits the Bioconductor ExpressionSet class, which provides a common interface familiar to those who have analyzed microarray experiments with Bioconductor. The class requires three input files:  exprs, a numeric matrix of expression values, where rows are features, and columns are cells phenoData, an AnnotatedDataFrame object, where rows are cells, and columns are cell attributes (such as cell type, culture condition, day captured, etc.) featureData, an AnnotatedDataFrame object, where rows are features (e.g. genes), and columns are feature attributes, such as biotype, gc content, etc.  For more details about other features inherited from Bioconductor’s ExpressionSet class, type ?ExpressionSet at the R prompt. When the data are encapsulated in the SCESet class, scater will automatically calculate several different properties. This will be demonstrated in the subsequent chapters.   "],
["expression-qc-umi.html", "6 Expression QC (UMI) 6.1 Introduction 6.2 Blischak dataset 6.3 Cell QC 6.4 Cell filtering 6.5 Compare filterings 6.6 Gene analysis 6.7 Save the data 6.8 Big Exercise", " 6 Expression QC (UMI)  6.1 Introduction Once gene expression has been quantified it is summarized as an expression matrix where each row corresponds to a gene (or transcript) and each column corresponds to a single cell. This matrix should be examined to remove poor quality cells which were not detected in either read QC or mapping QC steps. Failure to remove low quality cells at this stage may add technical noise which has the potential to obscure the biological signals of interest in the downstream analysis. Since there is currently no standard method for performing scRNASeq the expected values for the various QC measures that will be presented here can vary substantially from experiment to experiment. Thus, to perform QC we will be looking for cells which are outliers with respect to the rest of the dataset rather than comparing to independent quality standards. Consequently, care should be taken when comparing quality metrics across datasets collected using different protocols.   6.2 Blischak dataset To illustrate cell QC, we consider a dataset of induced pluripotent stem cells generated from three different individuals by John Blischak in Yoav Gilad’s lab at the University of Chicago. The experiments were carried out on the Fluidigm C1 platform and to facilitate the quantification both unique molecular identifiers (UMIs) and ERCC spike-ins were used. For our purposes you need to download the files annotation.txt, molecules.txt, and reads.txt into the blischak folder in your working directory. These files are the copies of the original files made on the 15/03/16. We will use these copies for reproducibility purposes. library(scater, quietly = TRUE) options(stringsAsFactors = FALSE) Load the data and annotations: molecules &lt;- read.table(&quot;blischak/molecules.txt&quot;, sep = &quot;\\t&quot;) anno &lt;- read.table(&quot;blischak/annotation.txt&quot;, sep = &quot;\\t&quot;, header = TRUE) Inspect a small portion of the expression matrix  Table 6.1: A table of the first 6 rows and 3 columns of the molecules table.    NA19098.r1.A01 NA19098.r1.A02 NA19098.r1.A03     ENSG00000237683 0 0 0   ENSG00000187634 0 0 0   ENSG00000188976 3 6 1   ENSG00000187961 0 0 0   ENSG00000187583 0 0 0   ENSG00000187642 0 0 0     Table 6.2: A table of the first 6 rows of the anno table.   individual replicate well batch sample_id     NA19098 r1 A01 NA19098.r1 NA19098.r1.A01   NA19098 r1 A02 NA19098.r1 NA19098.r1.A02   NA19098 r1 A03 NA19098.r1 NA19098.r1.A03   NA19098 r1 A04 NA19098.r1 NA19098.r1.A04   NA19098 r1 A05 NA19098.r1 NA19098.r1.A05   NA19098 r1 A06 NA19098.r1 NA19098.r1.A06    The data consists of 3 individuals and 3 replicates and therefore has 9 batches in total. We standardize the analysis by using the scater package. First, create the scater SCESet classes: pheno_data &lt;- new(&quot;AnnotatedDataFrame&quot;, anno) rownames(pheno_data) &lt;- pheno_data$sample_id umi &lt;- scater::newSCESet(     countData = molecules,     phenoData = pheno_data ) Remove genes that are not expressed in any cell: keep_feature &lt;- rowSums(is_exprs(umi)) &gt; 0 umi &lt;- umi[keep_feature, ] Define control features (genes) - ERCC spike-ins and mitochondrial genes (provided by the authors): ercc &lt;- featureNames(umi)[grepl(&quot;ERCC-&quot;, featureNames(umi))] mt &lt;- c(&quot;ENSG00000198899&quot;, &quot;ENSG00000198727&quot;, &quot;ENSG00000198888&quot;,         &quot;ENSG00000198886&quot;, &quot;ENSG00000212907&quot;, &quot;ENSG00000198786&quot;,         &quot;ENSG00000198695&quot;, &quot;ENSG00000198712&quot;, &quot;ENSG00000198804&quot;,         &quot;ENSG00000198763&quot;, &quot;ENSG00000228253&quot;, &quot;ENSG00000198938&quot;,         &quot;ENSG00000198840&quot;) Calculate the quality metrics: umi &lt;- scater::calculateQCMetrics(     umi,     feature_controls = list(ERCC = ercc, MT = mt) )   6.3 Cell QC  6.3.1 Library size Next we consider the total number of RNA molecules detected per sample (if we were using read counts rather than UMI counts this would be the total number of reads). Wells with few reads/molecules are likely to have been broken or failed to capture a cell, and should thus be removed. hist(     umi$total_counts,     breaks = 100 ) abline(v = 25000, col = &quot;red&quot;)    Figure 6.1: Histogram of library sizes for all cells   Exercise 1  How many cells does our filter remove? What distribution do you expect that the total number of molecules for each cell should follow?  Our answer  Table 6.3: The number of cells removed by total counts filter (FALSE)   filter_by_total_counts Freq     FALSE 46   TRUE 818    If your answer is different please compare your code with ours (you need to search for this exercise in the opened file).   6.3.2 Detected genes (1) In addition to ensuring sufficient sequencing depth for each sample, we also want to make sure that the reads are distributed across the transcriptome. Thus, we count the total number of unique genes detected in each sample. hist(     umi$total_features,     breaks = 100 ) abline(v = 7000, col = &quot;red&quot;)    Figure 6.2: Histogram of the number of detected genes in all cells   From the plot we conclude that most cells have between 7,000-10,000 detected genes, which is normal for high-depth scRNA-seq. However, this varies by experimental protocol and sequencing depth. For example, droplet-based methods or samples with lower sequencing-depth typically detect fewer genes per cell. The most notable feature in the above plot is the “heavy tail” on the left hand side of the distribution. If detection rates were equal across the cells then the distribution should be approximately normal. Thus we remove those cells in the tail of the distribution (fewer than 7,000 detected genes). Exercise 2 How many cells does our filter remove? Our answer  Table 6.4: The number of cells removed by total features filter (FALSE)   filter_by_expr_features Freq     FALSE 120   TRUE 744    If your answer is different please compare your code with ours (you need to search for this exercise in the opened file).   6.3.3 ERCCs and MTs Another measure of cell quality is the ratio between ERCC spike-in RNAs and endogenous RNAs. This ratio can be used to estimate the total amount of RNA in the captured cells. Cells with a high level of spike-in RNAs had low starting amounts of RNA, likely due to the cell being dead or stressed which may result in the RNA being degraded. scater::plotPhenoData(     umi,     aes_string(x = &quot;total_features&quot;,                y = &quot;pct_counts_feature_controls_MT&quot;,                colour = &quot;batch&quot;) )    Figure 6.3: Percentage of counts in MT genes   scater::plotPhenoData(     umi,     aes_string(x = &quot;total_features&quot;,                y = &quot;pct_counts_feature_controls_ERCC&quot;,                colour = &quot;batch&quot;) )    Figure 6.4: Percentage of counts in ERCCs   The above analysis shows that majority of the cells from NA19098.r2 batch have a very high ERCC/Endo ratio. Indeed, it has been shown by the authors that this batch contains cells of smaller size. Exercise 3 Create filters for removing batch NA19098.r2 and cells with high expression of mitochondrial genes (&gt;10% of total counts in a cell). Our answer  Table 6.5: The number of cells removed by ERCC filter (FALSE)   filter_by_ERCC Freq     FALSE 96   TRUE 768     Table 6.6: The number of cells removed by MT filter (FALSE)   filter_by_MT Freq     FALSE 31   TRUE 833    If your answer is different please compare your code with ours (you need to search for this exercise in the opened file). Exercise 4 What would you expect to see in the ERCC vs counts plot if you were examining a dataset containing cells of different sizes (eg. normal &amp; senescent cells)? Answer You would expect to see a group corresponding to the smaller cells (normal) with a higher fraction of ERCC reads than a separate group corresponding to the larger cells (senescent).    6.4 Cell filtering  6.4.1 Default Thresholds Results from the biological analysis of single-cell RNA-seq data are often strongly influenced by outliers. Thus, it is important to include multiple filters. A robust way of detecting outliers is through the median absolute difference which is defined as \\(d_i = |r_i - m|\\), where \\(r_i\\) is the number of reads in cell \\(i\\) and \\(m\\) is the median number of reads across the all cells in the sample. By default, scater removes all cells where \\(d_i&gt;\\)median(\\(d_i\\)). A similar filter is used for the number of detected genes. Furthermore, scater removes all cells where $&gt;$80% of counts were assigned to control genes and any cells that have been marked as controls. umi$use_default &lt;- (     # remove cells with unusual numbers of genes     !umi$filter_on_total_features &amp;     # remove cells with unusual numbers molecules counted     !umi$filter_on_total_counts &amp;     # &lt; 80% ERCC spike-in     !umi$filter_on_pct_counts_feature_controls_ERCC &amp;     # &lt; 80% mitochondrial     !umi$filter_on_pct_counts_feature_controls_MT &amp;     # controls shouldn&#39;t be used in downstream analysis     !umi$is_cell_control )  Table 6.7: The number of cells removed by default filter (FALSE)   Var1 Freq     FALSE 6   TRUE 858      6.4.2 Automatic Another option available in scater is to conduct PCA on a set of QC metrics and then use automatic outlier detection to identify potentially problematic cells. By default, the following metrics are used for PCA-based outlier detection:  pct_counts_top_100_features total_features pct_counts_feature_controls n_detected_feature_controls log10_counts_endogenous_features log10_counts_feature_controls  scater first creates a matrix where the rows represent cells and the columns represent the different QC metrics. Here, the PCA plot provides a 2D representation of cells ordered by their quality metrics. The outliers are then detected using methods from the mvoutlier package. umi &lt;- scater::plotPCA(umi,                 size_by = &quot;total_features&quot;,                  shape_by = &quot;filter_on_total_features&quot;,                 pca_data_input = &quot;pdata&quot;,                 detect_outliers = TRUE,                 return_SCESet = TRUE) ## The following cells/samples are detected as outliers: ## NA19098.r2.A01 ## NA19098.r2.A02 ## NA19098.r2.A06 ## NA19098.r2.A09 ## NA19098.r2.A10 ## NA19098.r2.A12 ## NA19098.r2.B01 ## NA19098.r2.B03 ## NA19098.r2.B04 ## NA19098.r2.B05 ## NA19098.r2.B07 ## NA19098.r2.B11 ## NA19098.r2.B12 ## NA19098.r2.C01 ## NA19098.r2.C02 ## NA19098.r2.C03 ## NA19098.r2.C04 ## NA19098.r2.C05 ## NA19098.r2.C06 ## NA19098.r2.C07 ## NA19098.r2.C08 ## NA19098.r2.C09 ## NA19098.r2.C10 ## NA19098.r2.C11 ## NA19098.r2.C12 ## NA19098.r2.D01 ## NA19098.r2.D02 ## NA19098.r2.D03 ## NA19098.r2.D04 ## NA19098.r2.D07 ## NA19098.r2.D08 ## NA19098.r2.D09 ## NA19098.r2.D10 ## NA19098.r2.D12 ## NA19098.r2.E01 ## NA19098.r2.E02 ## NA19098.r2.E03 ## NA19098.r2.E04 ## NA19098.r2.E05 ## NA19098.r2.E06 ## NA19098.r2.E07 ## NA19098.r2.E12 ## NA19098.r2.F01 ## NA19098.r2.F02 ## NA19098.r2.F07 ## NA19098.r2.F08 ## NA19098.r2.F09 ## NA19098.r2.F10 ## NA19098.r2.F11 ## NA19098.r2.F12 ## NA19098.r2.G01 ## NA19098.r2.G02 ## NA19098.r2.G03 ## NA19098.r2.G05 ## NA19098.r2.G06 ## NA19098.r2.G08 ## NA19098.r2.G09 ## NA19098.r2.G10 ## NA19098.r2.G11 ## NA19098.r2.H01 ## NA19098.r2.H02 ## NA19098.r2.H03 ## NA19098.r2.H04 ## NA19098.r2.H05 ## NA19098.r2.H06 ## NA19098.r2.H07 ## NA19098.r2.H08 ## NA19098.r2.H10 ## NA19098.r2.H12 ## NA19101.r3.A02 ## NA19101.r3.C12 ## NA19101.r3.D01 ## NA19101.r3.E08 ## Variables with highest loadings for PC1 and PC2: ##  ##                                            PC1         PC2 ## ---------------------------------  -----------  ---------- ## pct_counts_top_100_features          0.4771343   0.3009332 ## pct_counts_feature_controls          0.4735839   0.3309562 ## n_detected_feature_controls          0.1332811   0.5367629 ## log10_counts_feature_controls       -0.1427373   0.5911762 ## total_features                      -0.5016681   0.2936705 ## log10_counts_endogenous_features    -0.5081855   0.2757918    Figure 6.5: PCA plot used for automatic detection of cell outliers    Table 6.8: The number of cells removed by automatic filter (FALSE)   Var1 Freq     FALSE 791   TRUE 73      6.4.3 Manual Another option in scater is to use your own filters. We define filters based on our previous analysis: umi$use &lt;- (     # sufficient features (genes)     filter_by_expr_features &amp;     # sufficient molecules counted     filter_by_total_counts &amp;     # sufficient endogenous RNA     filter_by_ERCC &amp;     # remove cells with unusual number of reads in MT genes     filter_by_MT )  Table 6.9: The number of cells removed by manual filter (FALSE)   Var1 Freq     FALSE 210   TRUE 654       6.5 Compare filterings Exercise 5 Compare the default, automatic and manual cell filters. Plot a Venn diagram of the outlier cells from these filterings. Hint: Use limma::vennCounts and limma::vennDiagram functions from the limma package to make a Venn diagram. Answer    Figure 6.6: Comparison of the default, automatic and manual cell filters   If your answer is different please compare your code with ours (you need to search for this exercise in the opened file).   6.6 Gene analysis  6.6.1 Gene expression In addition to removing cells with poor quality, it is usually a good idea to exclude genes where we suspect that technical artefacts may have skewed the results. Moreover, inspection of the gene expression profiles may provide insights about how the experimental procedures could be imporved. It is often instructive to consider the number of reads consumed by the top 50 expressed genes. scater::plotQC(umi, type = &quot;highest-expression&quot;)    Figure 6.7: Number of total counts consumed by the top 50 expressed genes   The distribution relatively flat indicating (but not guaraneeing!) good coverage of the full transcriptome of these cells. However, there are several spike-ins in the top 15 genes which suggests a greater dilution of the spike-ins may be preferrable if the experiment is to be repeated.   6.6.2 Gene filtering It is typically a good idea to remove genes whose expression level is considered “undetectable”. We define a gene as detectable if at least two cells contain more than 1 transcript from the gene. If we were considering read counts rather than UMI counts a reasonable threshold is to require at least five reads in at least two cells. However, in both cases the threshold strongly depends on the sequencing depth. It also important to keep in mind that genes must be filtered after cell filtering since some genes may be only detected in poor quality cells (note pData(umi)$use filter applied to the umi dataset). filter_genes &lt;- apply(counts(umi[ , pData(umi)$use]), 1,                        function(x) length(x[x &gt; 1]) &gt;= 2) fData(umi)$use &lt;- filter_genes  Table 6.10: The number of genes removed by gene filter (FALSE)   filter_genes Freq     FALSE 4663   TRUE 14063    Depending on the cell-type, protocol and sequencing depth, other cut-offs may be appropriate.    6.7 Save the data Dimensions of the QCed dataset (do not forget about the gene filter we defined above): dim(umi[fData(umi)$use, pData(umi)$use]) ## Features  Samples  ##    14063      654 Save the data: saveRDS(umi, file = &quot;blischak/umi.rds&quot;) If you want to further check yourself you can download our umi object. If you followed the steps above it should be exactly the same as yours.   6.8 Big Exercise Perform exactly the same QC analysis with read counts of the same Blischak data. Use blischak/reads.txt file to load the reads. Once you have finished please compare your results to ours (next chapter).   "],
["expression-qc-reads.html", "7 Expression QC (Reads)", " 7 Expression QC (Reads) This chapter contains the summary plots and tables for the QC exercise based on the reads for the Bischak data discussed in the previous chapter.  Table 7.1: A table of the first 6 rows and 3 columns of the molecules table.    NA19098.r1.A01 NA19098.r1.A02 NA19098.r1.A03     ENSG00000237683 0 0 0   ENSG00000187634 0 0 0   ENSG00000188976 57 140 1   ENSG00000187961 0 0 0   ENSG00000187583 0 0 0   ENSG00000187642 0 0 0     Table 7.2: A table of the first 6 rows of the anno table.   individual replicate well batch sample_id     NA19098 r1 A01 NA19098.r1 NA19098.r1.A01   NA19098 r1 A02 NA19098.r1 NA19098.r1.A02   NA19098 r1 A03 NA19098.r1 NA19098.r1.A03   NA19098 r1 A04 NA19098.r1 NA19098.r1.A04   NA19098 r1 A05 NA19098.r1 NA19098.r1.A05   NA19098 r1 A06 NA19098.r1 NA19098.r1.A06       Figure 7.1: Histogram of library sizes for all cells    Table 7.3: The number of cells removed by total counts filter (FALSE)   filter_by_total_counts Freq     FALSE 180   TRUE 684       Figure 7.2: Histogram of the number of detected genes in all cells    Table 7.4: The number of cells removed by total features filter (FALSE)   filter_by_expr_features Freq     FALSE 120   TRUE 744       Figure 7.3: Library size vs number of detected genes      Figure 7.4: Percentage of counts in MT genes      Figure 7.5: Percentage of counts in ERCCs    Table 7.5: The number of cells removed by ERCC filter (FALSE)   filter_by_ERCC Freq     FALSE 103   TRUE 761     Table 7.6: The number of cells removed by MT filter (FALSE)   filter_by_MT Freq     FALSE 18   TRUE 846     Table 7.7: The number of cells removed by default filter (FALSE)   Var1 Freq     FALSE 37   TRUE 827    ## The following cells/samples are detected as outliers: ## NA19098.r1.B10 ## NA19098.r1.D07 ## NA19098.r1.E04 ## NA19098.r1.F06 ## NA19098.r1.H08 ## NA19098.r1.H09 ## NA19098.r2.A01 ## NA19098.r2.A06 ## NA19098.r2.A09 ## NA19098.r2.A12 ## NA19098.r2.B01 ## NA19098.r2.B11 ## NA19098.r2.B12 ## NA19098.r2.C04 ## NA19098.r2.C09 ## NA19098.r2.D02 ## NA19098.r2.D03 ## NA19098.r2.D09 ## NA19098.r2.E04 ## NA19098.r2.E07 ## NA19098.r2.F01 ## NA19098.r2.F11 ## NA19098.r2.G01 ## NA19098.r2.G05 ## NA19098.r2.G10 ## NA19098.r2.H01 ## NA19098.r2.H07 ## NA19098.r2.H08 ## NA19098.r2.H12 ## NA19098.r3.A05 ## NA19098.r3.A07 ## NA19098.r3.B02 ## NA19098.r3.C07 ## NA19098.r3.E05 ## NA19098.r3.E08 ## NA19098.r3.E09 ## NA19098.r3.F11 ## NA19098.r3.F12 ## NA19098.r3.G02 ## NA19098.r3.G03 ## NA19098.r3.G04 ## NA19098.r3.G11 ## NA19098.r3.G12 ## NA19098.r3.H08 ## NA19101.r1.A01 ## NA19101.r1.A12 ## NA19101.r1.B01 ## NA19101.r1.B06 ## NA19101.r1.E09 ## NA19101.r1.E11 ## NA19101.r1.F05 ## NA19101.r1.F10 ## NA19101.r1.G01 ## NA19101.r1.G06 ## NA19101.r1.H04 ## NA19101.r1.H09 ## NA19101.r2.A03 ## NA19101.r2.C10 ## NA19101.r2.E05 ## NA19101.r2.F02 ## NA19101.r2.H04 ## NA19101.r2.H10 ## NA19101.r3.A02 ## NA19101.r3.A03 ## NA19101.r3.A05 ## NA19101.r3.A09 ## NA19101.r3.B05 ## NA19101.r3.C01 ## NA19101.r3.C09 ## NA19101.r3.C12 ## NA19101.r3.D01 ## NA19101.r3.D04 ## NA19101.r3.D07 ## NA19101.r3.D09 ## NA19101.r3.E08 ## NA19101.r3.F09 ## NA19101.r3.G09 ## NA19101.r3.H01 ## NA19101.r3.H03 ## NA19101.r3.H07 ## NA19101.r3.H09 ## NA19239.r1.F05 ## NA19239.r1.G05 ## NA19239.r2.B01 ## NA19239.r2.B03 ## NA19239.r2.B10 ## NA19239.r2.B11 ## NA19239.r2.C03 ## NA19239.r2.C06 ## NA19239.r2.C08 ## NA19239.r2.D07 ## NA19239.r2.D09 ## NA19239.r2.E09 ## NA19239.r2.F04 ## NA19239.r2.F06 ## NA19239.r2.F07 ## NA19239.r2.F12 ## NA19239.r2.G03 ## NA19239.r2.G08 ## NA19239.r2.H02 ## NA19239.r2.H03 ## NA19239.r2.H07 ## NA19239.r3.A01 ## NA19239.r3.B09 ## NA19239.r3.C04 ## NA19239.r3.C07 ## NA19239.r3.E01 ## NA19239.r3.E03 ## NA19239.r3.E12 ## NA19239.r3.H02 ## NA19239.r3.H10 ## Variables with highest loadings for PC1 and PC2: ##  ##                                            PC1         PC2 ## ---------------------------------  -----------  ---------- ## pct_counts_feature_controls          0.5057646   0.2473134 ## pct_counts_top_100_features          0.4888852   0.2277068 ## n_detected_feature_controls          0.0231277   0.6235516 ## log10_counts_feature_controls       -0.1226860   0.6576822 ## total_features                      -0.4655518   0.2219694 ## log10_counts_endogenous_features    -0.5223679   0.1278782    Figure 7.6: PCA plot used for automatic detection of cell outliers    Table 7.8: The number of cells removed by automatic filter (FALSE)   Var1 Freq     FALSE 753   TRUE 111     Table 7.9: The number of cells removed by manual filter (FALSE)   Var1 Freq     FALSE 259   TRUE 605       Figure 7.7: Comparison of the default, automatic and manual cell filters      Figure 7.8: Dropout rate vs mean expression      Figure 7.9: Number of total counts consumed by the top 50 expressed genes    Table 7.10: The number of genes removed by gene filter (FALSE)   filter_genes Freq     FALSE 2665   TRUE 16061    ## Features  Samples  ##    16061      605 If you want to further check yourself you can download our reads object. If you followed the steps above it should be exactly the same as yours. By comparing Figure 7.7 and Figure 6.6, it is clear that the reads based filtering removed 49 more cells than the UMI based analysis. If you go back and compare the results you should be able to conclude that the ERCC and MT filters are more strict for the reads-based analysis.  "],
["data-visualization.html", "8 Data visualization 8.1 Introduction 8.2 PCA plot 8.3 tSNE map 8.4 Big Exercise", " 8 Data visualization  8.1 Introduction In this chapter we will continue to work with the filtered blischak dataset produced in the previous chapter. We will explore different ways of visualizing the data to allow you to asses what happened to the expression matrix after the quality control step. scater package provides several very useful functions to simplify visualisation. One important aspect of single-cell RNA-seq is to control for batch effects. Batch effects are technical artefacts that are added to the samples during handling. For example, if two sets of samples were prepared in different labs or even on different days in the same lab, then we may observe greater similarities between the samples that were handled together. In the worst case scenario, batch effects may be mistaken for true biological variation. The Blischak data allows us to explore these issues in a controlled manner since some of the salient aspects of how the samples were handled have been recorded. Ideally, we expect to see batches from the same individual grouping together and distinct groups corresponding to each individual. library(scater, quietly = TRUE) options(stringsAsFactors = FALSE) umi &lt;- readRDS(&quot;blischak/umi.rds&quot;) umi.qc &lt;- umi[fData(umi)$use, pData(umi)$use] endog_genes &lt;- !fData(umi.qc)$is_feature_control   8.2 PCA plot The easiest thing to overview the data is to transform it using the principal component analysis and then visualize the first two principal components. Principal component analysis (PCA) is a statistical procedure that uses a transformation to convert a set of observations into a set of values of linearly uncorrelated variables called principal components (PCs). The number of principal components is less than or equal to the number of original variables. PCA is defined in such a way that the first principal component accounts for as much of the variability in the data as possible, and each succeeding component in turn has the highest variance possible under the constraint that it is orthogonal to the preceding components. knitr::include_graphics(&quot;figures/pca.png&quot;)    Figure 8.1: Schematic representation of PCA dimensionality reduction (taken from here)    8.2.1 Before QC scater::plotPCA(umi[endog_genes, ],                 ntop = 500,                 colour_by = &quot;batch&quot;,                 size_by = &quot;total_features&quot;,                 shape_by = &quot;individual&quot;,                 exprs_values = &quot;counts&quot;)    Figure 8.2: PCA plot of the blischak data     8.2.2 After QC scater::plotPCA(umi.qc[endog_genes, ],                 ntop = 500,                 colour_by = &quot;batch&quot;,                 size_by = &quot;total_features&quot;,                 shape_by = &quot;individual&quot;,                 exprs_values = &quot;counts&quot;)    Figure 8.3: PCA plot of the blischak data   Comparing Figure 8.1 and Figure 8.2, it is clear that after normalization the NA19098.r2 cells no longer form a group of outliers. By default only the top 500 most variable genes are used by scater to calculate the PCA. This can be adjusted by changing the ntop argument. Exercise 1 How do the PCA plots change if when all 14,214 genes are used? Or when only top 50 genes are used? Our answer    Figure 8.4: PCA plot of the blischak data (14214 genes)      Figure 8.5: PCA plot of the blischak data (50 genes)   If your answers are different please compare your code with ours (you need to search for this exercise in the opened file).    8.3 tSNE map An alternative to PCA for visualizing scRNASeq data is a tSNE plot. tSNE (t-Distributed Stochastic Neighbor Embedding) combines dimensionality reduction (e.g. PCA) with random walks on the nearest-neighbour network to map high dimensional data (i.e. our 14,214 dimensional expression matrix) to a 2-dimensional space while preserving local distances between cells. In contrast with PCA, tSNE is a stochastic algorithm which means running the method multiple times on the same dataset will result in different plots. In the code below we fix the “seed” of the random-number generator so that we always get the same plot.  8.3.1 Before QC scater::plotTSNE(umi[endog_genes, ],                  ntop = 500,                  perplexity = 130,                  colour_by = &quot;batch&quot;,                  size_by = &quot;total_features&quot;,                  shape_by = &quot;individual&quot;,                  exprs_values = &quot;counts&quot;,                  rand_seed = 123456)    Figure 8.6: tSNE map of the blischak data     8.3.2 After QC scater::plotTSNE(umi.qc[endog_genes, ],                  ntop = 500,                  perplexity = 130,                  colour_by = &quot;batch&quot;,                  size_by = &quot;total_features&quot;,                  shape_by = &quot;individual&quot;,                  exprs_values = &quot;counts&quot;,                  rand_seed = 123456)    Figure 8.7: tSNE map of the blischak data   Interpreting PCA and tSNE plots is often challenging. However, in this case it is clear that they provide a similar picture of the data. Comparing Figure 8.5 and 8.6, it is again clear that the samples from NA19098.r2 are no longer outliers after the QC filtering. Furthermore tSNE requires you to provide a value of “perplexity” which reflects the number of neighbours used to build the nearest-neighbour network; a high value creates a dense network which clumps cells together while a low value makes the network more sparse allowing groups of cells to separate from each other. scater uses a default perplexity of the total number of cells divided by five (rounded down). Exercise 2 How do the tSNE plots change when a perplexity of 10 or 200 is used? Our answer    Figure 8.8: tSNE map of the blischak data (perplexity = 10)      Figure 8.9: tSNE map of the blischak data (perplexity = 200)   If your answers are different please compare your code with ours (you need to search for this exercise in the opened file).    8.4 Big Exercise Perform the same analysis with read counts of the Blischak data. Use blischak/reads.rds file to load the reads SCESet object. Once you have finished please compare your results to ours (next chapter).   "],
["expression-overview-reads.html", "9 Expression overview (Reads)", " 9 Expression overview (Reads)    Figure 9.1: PCA plot of the blischak data      Figure 9.2: PCA plot of the blischak data      Figure 9.3: tSNE map of the blischak data      Figure 9.4: tSNE map of the blischak data    "],
["confounding-factors.html", "10 Confounding factors 10.1 Introduction 10.2 Correlations with PCs 10.3 Explanatory variables 10.4 Other confounders 10.5 Exercise", " 10 Confounding factors  10.1 Introduction There is a large number of potential confounders, artifacts and biases in sc-RNA-seq data. One of the main challenges in analyzing scRNA-seq data stems from the fact that it is difficult to carry out a true technical replicate (why?) to distinguish biological and technical variability. In the previous chapters we considered batch effects and in this chapter we will continue to explore how experimental artifacts can be identified and removed. We will continue using the scater package since it provides a set of methods specifically for quality control of experimental and explanatory variables. Moreover, we will continue to work with the Blischak data that was used in the previous chapter. library(scater, quietly = TRUE) options(stringsAsFactors = FALSE) umi &lt;- readRDS(&quot;blischak/umi.rds&quot;) umi.qc &lt;- umi[fData(umi)$use, pData(umi)$use] endog_genes &lt;- !fData(umi.qc)$is_feature_control The umi.qc dataset contains filtered cells and genes. Our next step is to explore technical drivers of variability in the data to inform data normalisation before downstream analysis.   10.2 Correlations with PCs Let’s first look again at the PCA plot of the QCed dataset: scater::plotPCA(umi.qc[endog_genes, ],                 colour_by = &quot;batch&quot;,                 size_by = &quot;total_features&quot;,                 exprs_values = &quot;counts&quot;)    Figure 10.1: PCA plot of the blischak data   scater allows one to identify principle components that correlate with experimental and QC variables of interest (it ranks principle components by \\(R^2\\) from a linear model regressing PC value against the variable of interest). Let’s test whether some of the variables correlate with any of the PCs.  10.2.1 Detected genes scater::plotQC(umi.qc[endog_genes, ],                type = &quot;find-pcs&quot;,                variable = &quot;total_features&quot;,                exprs_values = &quot;counts&quot;)    Figure 10.2: PC correlation with the number of detected genes   Indeed, we can see that PC1 can be completely explained by the number of the detected genes. In fact, it was also visible on the PCA plot above. This is a well-known issue in scRNA-seq and was described here.    10.3 Explanatory variables scater can also compute the marginal \\(R^2\\) for each variable when fitting a linear model regressing expression values for each gene against just that variable, and display a density plot of the gene-wise marginal \\(R^2\\) values for the variables. scater::plotQC(umi.qc[endog_genes, ],                type = &quot;expl&quot;,                exprs_values = &quot;counts&quot;,                variables = c(&quot;total_features&quot;,                              &quot;total_counts&quot;,                              &quot;batch&quot;,                              &quot;individual&quot;,                              &quot;pct_counts_feature_controls_ERCC&quot;,                              &quot;pct_counts_feature_controls_MT&quot;))    Figure 10.3: Explanatory variables   This analysis indicates that the number of detected genes (again) and also the sequencing depth (number of counts) have substantial explanatory power for many genes, so these variables are good candidates for conditioning out in a normalisation step, or including in downstream statistical models. Expression of ERCCs also appears to be an important explanatory variable.   10.4 Other confounders In addition to correcting for batch, there are other factors that one may want to compensate for. As with batch correction, these adjustments require extrinsic information. One popular method is scLVM which allows you to identify and subtract the effect from processes such as cell-cycle or apoptosis. In addition, protocols may differ in terms of their coverage of each transcript, their bias based on the average content of A/T nucleotides, or their ability to capture short transcripts. Ideally, we would like to compensate for all of these differences and biases.   10.5 Exercise Perform the same analysis with read counts of the Blischak data. Use blischak/reads.rds file to load the reads SCESet object. Once you have finished please compare your results to ours (next chapter).   "],
["confounding-factors-reads.html", "11 Confounding factors (Reads)", " 11 Confounding factors (Reads)    Figure 11.1: PCA plot of the blischak data      Figure 11.2: PC correlation with the number of detected genes    "],
["normalization-for-library-size.html", "12 Normalization for library size 12.1 Introduction 12.2 Library size 12.3 Normalisations 12.4 Other methods 12.5 Exercise", " 12 Normalization for library size  12.1 Introduction In the previous chapter we identified important confounding factors and explanatory variables. scater allows one to account for these variables in subsequent statistical models or to condition them out using normaliseExprs(), if so desired. This can be done by providing a design matrix to normaliseExprs(). We are not covering this topic here, but you can try to do it yourself as an exercise. Instead we will explore how simple size-factor normalisations correcting for library size can remove the effects of some of the confounders and explanatory variables.   12.2 Library size Library sizes vary because scRNA-seq data is often sequenced on highly multiplexed platforms the total reads which are derived from each cell may differ substantially. Some quantification methods (eg. Cufflinks, RSEM) incorporated library size when determining gene expression estimates thus do not require this normalization. However, if another quantification method was used then library size must be corrected for by multiplying or dividing each column of the expression matrix by a “normalization factor” which is an estimate of the library size relative to the other cells. Many methods to correct for library size have been developped for bulk RNA-seq and can be equally applied to scRNA-seq (eg. UQ, SF, CPM, RPKM, FPKM, TPM).   12.3 Normalisations The simplest way to normalize this data is to convert it to counts per million (CPM) by dividing each column by its total then multiplying by 1,000,000. Note that spike-ins should be excluded from the calculation of total expression in order to correct for total cell RNA content, therefore we will only use endogenous genes. calc_cpm &lt;- function (expr_mat, spikes = NULL)  {     norm_factor &lt;- colSums(expr_mat[-spikes, ])     return(t(t(expr_mat)/norm_factor)) * 10^6 } One potential drawback of CPM is if your sample contains genes that are both very highly expressed and differentially expressed across the cells. In this case, the total molecules in the cell may depend of whether such genes are on/off in the cell and normalizing by total molecules may hide the differential expression of those genes and/or falsely create differential expression for the remaining genes. Note: RPKM, FPKM and TPM are variants on CPM which further adjust counts by the length of the respective gene/transcript. To deal with this potentiality several other measures were devised: The size factor (SF) was proposed and popularized by DESeq (Anders and Huber (2010)). First the geometric mean of each gene across all cells is calculated. The size factor for each cell is the median across genes of the ratio of the expression to the gene’s geometric mean. A draw back to this method is that since it uses the geometric mean only genes with non-zero expression values across all cells can be used in its calculation, making it unadvisable for large low-depth scRNASeq experiments. edgeR &amp; scater call this method RLE for “relative log expression”. calc_sf &lt;- function (expr_mat, spikes = NULL)  {     geomeans &lt;- exp(rowMeans(log(expr_mat[-spikes, ])))     SF &lt;- function(cnts) {         median((cnts/geomeans)[(is.finite(geomeans) &amp; geomeans &gt;              0)])     }     norm_factor &lt;- apply(expr_mat[-spikes, ], 2, SF)     return(t(t(expr_mat)/norm_factor)) } The upperquartile (UQ) was proposed by Bullard et al (2010). Here each column is divided by the 75% quantile of the counts for each library. Often the calculated quantile is scaled by the median across cells to keep the absolute level of expression relatively consistent. A draw back to this method is that for low-depth scRNASeq experiments the large number of undetected genes may result in the 75% quantile being zero (or close to it). This limitation can be overcome by generalizing the idea and using a higher quantile (eg. the 99% quantile is the default in scater) or by excluding zeros prior to calculating the 75% quantile. calc_uq &lt;- function (expr_mat, spikes = NULL)  {     UQ &lt;- function(x) {         quantile(x[x &gt; 0], 0.75)     }     uq &lt;- unlist(apply(expr_mat[-spikes, ], 2, UQ))     norm_factor &lt;- uq/median(uq)     return(t(t(expr_mat)/norm_factor)) } Another method is called TMM is the weighted trimmed mean of M-values (to the reference) proposed by Robinson and Oshlack (2010). The M-values in question are the gene-wise log2 fold changes between individual cells. One cell is used as the reference then the M-values for each other cell is calculated compared to this reference. These values are then trimmed by removing the top and bottom ~30%, and the average of the remaining values is calculated by weighting them to account for the effect of the log scale on variance. Each non-reference cell is multiplied by the calculated factor. Two potential issues with this method are insufficient non-zero genes left after trimming, and the assumption that most genes are not differentially expressed. We will use visual inspection of PCA plots and calculation of cell-wise relative log expression (calc_cell_RLE()) to compare the efficiency of different normalization methods. Cells with many[few] reads have higher[lower] than median expression for most genes resulting in a positive[negative] RLE across the cell, whereas normalized cells have an RLE close to zero. calc_cell_RLE &lt;- function (expr_mat, spikes = NULL)  {     RLE_gene &lt;- function(x) {         if (median(unlist(x)) &gt; 0) {             log((x + 1)/(median(unlist(x)) + 1))/log(2)         }         else {             rep(NA, times = length(x))         }     }     if (!is.null(spikes)) {         RLE_matrix &lt;- t(apply(expr_mat[-spikes, ], 1, RLE_gene))     }     else {         RLE_matrix &lt;- t(apply(expr_mat, 1, RLE_gene))     }     cell_RLE &lt;- apply(RLE_matrix, 2, median, na.rm = T)     return(cell_RLE) } scater acts as a wrapper for the calcNormFactors function from edgeR which implements several library size normalization methods making it easy to apply any of these methods to our data. Note: edgeR makes extra adjustments to some of the normalization methods which may result in somewhat different results than if the original methods are followed exactly, e.g. edgeR’s and scater’s “RLE” method which is based on the “size factor” used by DESeq may give different results to the estimateSizeFactorsForMatrix method in the DESeq/DESeq2 packages. In addition, some versions of edgeR will not calculate the normalization factors correctly unless lib.size is set at 1 for all cells. We will continue to work with the Blischak data that was used in the previous chapter. library(scater, quietly = TRUE) options(stringsAsFactors = FALSE) umi &lt;- readRDS(&quot;blischak/umi.rds&quot;) umi.qc &lt;- umi[fData(umi)$use, pData(umi)$use] endog_genes &lt;- !fData(umi.qc)$is_feature_control  12.3.1 Raw scater::plotPCA(umi.qc[endog_genes, ],                 colour_by = &quot;batch&quot;,                 size_by = &quot;total_features&quot;,                 shape_by = &quot;individual&quot;,                 exprs_values = &quot;counts&quot;)    Figure 12.1: PCA plot of the blischak data   boxplot(calc_cell_RLE(counts(umi.qc)),         col = &quot;grey50&quot;,         ylab = &quot;RLE&quot;,         main = &quot;&quot;, ylim=c(-1,1))    Figure 12.2: Cell-wise RLE of the blischak data     12.3.2 CPM scater performs this normalisation by default, you can control it by changing exprs_values parameter to &quot;exprs&quot;. scater::plotPCA(umi.qc[endog_genes, ],                 colour_by = &quot;batch&quot;,                 size_by = &quot;total_features&quot;,                 shape_by = &quot;individual&quot;,                 exprs_values = &quot;cpm&quot;)    Figure 12.3: PCA plot of the blischak data after CPM normalisation   boxplot(calc_cell_RLE(cpm(umi.qc)),         col = &quot;grey50&quot;,         ylab = &quot;RLE&quot;,         main = &quot;&quot;, ylim = c(-1,1))    Figure 12.4: Cell-wise RLE of the blischak data     12.3.3 TMM umi.qc &lt;-      scater::normaliseExprs(umi.qc,                            method = &quot;TMM&quot;,                            feature_set = endog_genes,                            lib.size = rep(1, ncol(umi.qc))) scater::plotPCA(umi.qc[endog_genes, ],                 colour_by = &quot;batch&quot;,                 size_by = &quot;total_features&quot;,                 shape_by = &quot;individual&quot;,                 exprs_values = &quot;norm_counts&quot;)    Figure 12.5: PCA plot of the blischak data after TMM normalisation   boxplot(calc_cell_RLE(norm_counts(umi.qc)),         col = &quot;grey50&quot;,         ylab = &quot;RLE&quot;,         main = &quot;&quot;, ylim=c(-1,1))    Figure 12.6: Cell-wise RLE of the blischak data   Exercise: Use method = &quot;RLE&quot; and method = &quot;upperquartile&quot; to perform size-factor and UQ normalizations and compare to the results above.   12.3.4 Size-factor (RLE) umi.qc &lt;-      scater::normaliseExprs(umi.qc,                            method = &quot;RLE&quot;,                             feature_set = endog_genes,                            lib.size = rep(1, ncol(umi.qc))) scater::plotPCA(umi.qc[endog_genes, ],                 colour_by = &quot;batch&quot;,                 size_by = &quot;total_features&quot;,                 shape_by = &quot;individual&quot;,                 exprs_values = &quot;norm_counts&quot;)    Figure 12.7: PCA plot of the blischak data after RLE normalisation   boxplot(calc_cell_RLE(norm_counts(umi.qc)),         col = &quot;grey50&quot;,         ylab = &quot;RLE&quot;,         main = &quot;&quot;, ylim=c(-1,1))    Figure 12.8: Cell-wise RLE of the blischak data     12.3.5 Upperquantile umi.qc &lt;-      scater::normaliseExprs(umi.qc,                            method = &quot;upperquartile&quot;,                             feature_set = endog_genes,                            p = 0.99,                            lib.size = rep(1, ncol(umi.qc))) scater::plotPCA(umi.qc[endog_genes, ],                 colour_by = &quot;batch&quot;,                 size_by = &quot;total_features&quot;,                 shape_by = &quot;individual&quot;,                 exprs_values = &quot;norm_counts&quot;)    Figure 12.9: PCA plot of the blischak data after UQ normalisation   boxplot(calc_cell_RLE(norm_counts(umi.qc)),         col = &quot;grey50&quot;,         ylab = &quot;RLE&quot;,         main = &quot;&quot;, ylim=c(-1,1))    Figure 12.10: Cell-wise RLE of the blischak data      12.4 Other methods Some methods combine library size and fragment/gene length normalization such as:  RPKM - Reads Per Kilobase Million (for single-end sequencing) FPKM - Fragments Per Kilobase Million (same as RPKM but for paired-end sequencing, makes sure that paired ends mapped to the same fragment are not counted twice) TPM - Transcripts Per Kilobase Million (same as RPKM, but the order of normalizations is reversed - length first and sequencing depth second)  These methods are not applicable to our dataset since the end of the transcript which contains the UMI was preferentially sequenced. Furthermore in general these should only be calculated using appropriate quantification software from aligned BAM files not from read counts since often only a portion of the entire gene/transcript is sequenced, not the entire length. However, here we show how these normalisations can be calculated using scater. First, we need to find the effective transcript length in Kilobases. However, our dataset containes only gene IDs, therefore we will be using the gene lengths instead of transcripts. scater uses the biomaRt package, which allows one to annotate genes by other attributes: umi.qc &lt;-     scater::getBMFeatureAnnos(umi.qc,                               filters = &quot;ensembl_gene_id&quot;,                                attributes = c(&quot;ensembl_gene_id&quot;,                                              &quot;hgnc_symbol&quot;,                                              &quot;chromosome_name&quot;,                                              &quot;start_position&quot;,                                              &quot;end_position&quot;),                                feature_symbol = &quot;hgnc_symbol&quot;,                               feature_id = &quot;ensembl_gene_id&quot;,                               biomart = &quot;ENSEMBL_MART_ENSEMBL&quot;,                                dataset = &quot;hsapiens_gene_ensembl&quot;,                               host = &quot;www.ensembl.org&quot;)  # If you have mouse data, change the arguments based on this example: # scater::getBMFeatureAnnos(object, #                           filters = &quot;ensembl_transcript_id&quot;,  #                           attributes = c(&quot;ensembl_transcript_id&quot;,  #                                        &quot;ensembl_gene_id&quot;, &quot;mgi_symbol&quot;,  #                                        &quot;chromosome_name&quot;, #                                        &quot;transcript_biotype&quot;, #                                        &quot;transcript_start&quot;, #                                        &quot;transcript_end&quot;,  #                                        &quot;transcript_count&quot;),  #                           feature_symbol = &quot;mgi_symbol&quot;, #                           feature_id = &quot;ensembl_gene_id&quot;, #                           biomart = &quot;ENSEMBL_MART_ENSEMBL&quot;,  #                           dataset = &quot;mmusculus_gene_ensembl&quot;, #                           host = &quot;www.ensembl.org&quot;)  Some of the genes were not annotated, therefore we filter them out: umi.qc.ann &lt;-     umi.qc[!is.na(fData(umi.qc)$ensembl_gene_id), ] Now we compute the total gene length in Kilobases by using the end_position and start_position fields: eff_length &lt;- abs(fData(umi.qc.ann)$end_position -                       fData(umi.qc.ann)$start_position)/1000 Now we are ready to perform the normalisations: tpm(umi.qc.ann) &lt;-     calculateTPM(         umi.qc.ann,         eff_length     ) fpkm(umi.qc.ann) &lt;-     calculateFPKM(         umi.qc.ann,         eff_length     ) Plot the results as a PCA plot: scater::plotPCA(umi.qc.ann,                 colour_by = &quot;batch&quot;,                 size_by = &quot;total_features&quot;,                 shape_by = &quot;individual&quot;,                 exprs_values = &quot;fpkm&quot;)    Figure 12.11: PCA plot of the blischak data after FPKM normalisation   scater::plotPCA(umi.qc.ann,                 colour_by = &quot;batch&quot;,                 size_by = &quot;total_features&quot;,                 shape_by = &quot;individual&quot;,                 exprs_values = &quot;tpm&quot;)    Figure 12.12: PCA plot of the blischak data after TPM normalisation   Note: The PCA primarily looks for difference between cells. Since gene length is the same across cells for each gene FPKM is almost identical to the CPM plot (it is just rotated). However, if we plot the mean expression vs gene length it is apparent that normalizing for gene length should not be performed for this dataset. plot(eff_length, rowMeans(counts(umi.qc.ann)))    Figure 12.13: Gene length vs Mean Expression for the raw data     12.5 Exercise Perform the same analysis with read counts of the Blischak data. Use blischak/reads.rds file to load the reads SCESet object. Once you have finished please compare your results to ours (next chapter).   "],
["normalization-for-library-size-reads.html", "13 Normalization for library size (Reads)", " 13 Normalization for library size (Reads)    Figure 13.1: PCA plot of the blischak data      Figure 13.2: PCA plot of the blischak data after CPM normalisation      Figure 13.3: PCA plot of the blischak data after log2(CPM) normalisation      Figure 13.4: PCA plot of the blischak data after TMM normalisation      Figure 13.5: PCA plot of the blischak data after RLE normalisation      Figure 13.6: PCA plot of the blischak data after UQ normalisation      Figure 13.7: PCA plot of the blischak data after FPKM normalisation      Figure 13.8: Expression of the first 6 genes of the blischak data      Figure 13.9: Expression of the first 6 genes of the blischak data after the CPM normalisation      Figure 13.10: Expression of the first 6 genes of the blischak data after the log2(CPM) normalisation      Figure 13.11: Expression of the first 6 genes of the blischak data after the UQ normalisation      Figure 13.12: Expression of the first 6 genes of the blischak data after the FPKM normalisation      Figure 13.13: Expression of the first 6 genes of the blischak data after the TPM normalisation    "],
["remove-confounders-using-controls.html", "14 Remove confounders using controls 14.1 Introduction 14.2 Brennecke method 14.3 Remove Unwanted Variation 14.4 Effectiveness 1 14.5 Effectiveness 2 14.6 Exercise", " 14 Remove confounders using controls  14.1 Introduction In the previous chapter we saw that the library size normalisation is able to remove major confounders. Let us see whether further use of the controls (ERCC and MT) can provide us with more insights into the data. Several methods (eg. BASiCS, scLVM, RUV) have been developed for normalisation using ERCCs using different noise models and different fitting procedures. We will demonstrate some of the methods starting from the simplest one proposed by Brennecke et al., which identifies genes with significant variation above technical noise (ERCCs). library(scRNA.seq.funcs) library(RUVSeq) library(scater, quietly = TRUE) options(stringsAsFactors = FALSE) umi &lt;- readRDS(&quot;blischak/umi.rds&quot;) umi.qc &lt;- umi[fData(umi)$use, pData(umi)$use] endog_genes &lt;- !fData(umi.qc)$is_feature_control   14.2 Brennecke method To use the method, we first normalize for library size then calculate the mean and the square coefficient of variation (variation divided by the squared mean expression). A curve is fit for the relationship between these two variables for the ERCC spike-in (subject to just technical variation) then a chi-square test is used to find genes significantly above the curve. This has been provided for you as the Brenneck_getVariableGenes(counts, spikes) function. umi.qc &lt;-      scater::normaliseExprs(umi.qc,                            method = &quot;RLE&quot;,                            feature_set = endog_genes,                            lib.size = rep(1, ncol(umi.qc))) erccs &lt;- grep(&quot;ERCC-&quot;, rownames(assayData(umi.qc)$norm_counts)) highly.var.genes &lt;- scRNA.seq.funcs::Brennecke_getVariableGenes(             assayData(umi.qc)$norm_counts,             erccs ) ## Warning in scRNA.seq.funcs::Brennecke_getVariableGenes(assayData(umi.qc) ## $norm_counts, : Only 23 spike-ins to be used in fitting, may result in poor ## fit.    Figure 14.1: Results of using the Brennecke method on the Blischak dataset   In the figure above blue points are the ERCC spike-ins. The red curve is the fitted technical noise model and the dashed line is the 95% CI. Pink dots are the genes with significant biological variability after multiple-testing correction. Since our dataset is relatively homogeneous only 306 genes are identified as significantly variable.   14.3 Remove Unwanted Variation Factors contributing to technical noise frequently appear as “batch effects” where cells processed on different days or by different technicians systematically vary from one another. Removing technical noise and correcting for batch effects can frequently be performed using the same tool or slight variants on it. We will be considering the Remove Unwanted Variation (RUV) method which uses singular value decomposition (similar to PCA) on subsets of the dataset which should be invariant (e.g. ERCC spike-ins). Then the method removes the identified unwanted factors. assayData(umi.qc)$ruv_counts &lt;- RUVSeq::RUVg(     round(assayData(umi.qc)$norm_counts),     erccs,     k = 1)$normalizedCounts   14.4 Effectiveness 1 We evaluate the effectiveness of the normalization by inspecting the PCA plot where shape corresponds the technical replicate and colour corresponds to different biological samples (individuals from whom the iPSC lines where derived). Separation of biological samples and interspersed batches indicates that technical variation has been removed. scater::plotPCA(umi.qc[endog_genes, ],                 colour_by = &quot;batch&quot;,                 size_by = &quot;total_features&quot;,                 shape_by = &quot;individual&quot;,                 exprs_values = &quot;norm_counts&quot;)    Figure 14.2: PCA plot of the blischak data after RLE normalisation   scater::plotPCA(umi.qc[endog_genes, ],                 colour_by = &quot;batch&quot;,                 size_by = &quot;total_features&quot;,                 shape_by = &quot;individual&quot;,                 exprs_values = &quot;ruv_counts&quot;)    Figure 14.3: PCA plot of the blischak data after RLE and RUV normalisations     14.5 Effectiveness 2 We can also examine the relative log expression (RLE) across cells to confirm technical noise has been removed from the dataset. boxplot(list(scRNA.seq.funcs::calc_cell_RLE(assayData(umi.qc)$norm_counts),              scRNA.seq.funcs::calc_cell_RLE(assayData(umi.qc)$ruv_counts)))    Figure 14.4: Comparison of the relative log expression of the blischak data before and after the RUV normalisation     14.6 Exercise Perform the same analysis with read counts of the Blischak data. Use blischak/reads.rds file to load the reads SCESet object. Once you have finished please compare your results to ours (next chapter). Additionally, experiment with other combinations of normalizations and compare the results.   "],
["remove-confounders-using-controls-reads.html", "15 Remove confounders using controls (Reads)", " 15 Remove confounders using controls (Reads) ## Warning in scRNA.seq.funcs::Brennecke_getVariableGenes(assayData(reads.qc) ## $norm_counts, : Only 15 spike-ins to be used in fitting, may result in poor ## fit.    Figure 15.1: Results of using the Brennecke method on the Blischak dataset      Figure 15.2: PCA plot of the blischak data after RLE normalisation      Figure 15.3: PCA plot of the blischak data after RLE and RUV normalisations      Figure 15.4: Comparison of the relative log expression of the blischak data before and after the RUV normalisation    "],
["clustering-analysis.html", "16 Clustering analysis 16.1 Introduction 16.2 Dimensionality reductions 16.3 Clustering methods 16.4 Challenges in clustering 16.5 Tools for scRNA-seq data", " 16 Clustering analysis Once we have normalized the data and removed confounders we can carry out analyses that will allow us to interpret the data biologically. The exact nature of the analysis depends on the dataset and the biological question at hand. Nevertheless, there are a few operations which are useful in a wide range of contexts and we will be discussing some of them. We will start with the clustering of scRNA-seq data.  16.1 Introduction One of the most promising applications of scRNA-seq is the discovery and annotation of cell-types based on the transcription profiles. Computationally, this is a hard problem as it amounts to unsupervised clustering. That is, we need to identify groups of cells based on the similarities of the transcriptomes without any prior knowledge of the labels. The problem is made more challenging due to the high level of noise and the large number of dimensions (i.e. genes).   16.2 Dimensionality reductions When working with large datasets, it can often be beneficial to apply some sort of dimensionality reduction method. By projecting the data onto a lower-dimensional sub-space, one is often able to significantly reduce the amount of noise. An additional benefit is that it is typically much easier to visualize the data in a 2 or 3-dimensional subspace. Here we will introduce some of the popular dimensionality reduction methods.  16.2.1 PCA PCA analysis was introduced in chapter 8.2.   16.2.2 Spectral Spectral decomposition is the factorization of a matrix into a canonical form, whereby the matrix is represented in terms of its eigenvalues and eigenvectors. In application to scRNA-seq data, the matrix can be either an input expression matrix, or matrix of distances between the cells. The computed eigenvectors are similar to the projections of the data to PCs (chapter 8.2.).   16.2.3 tSNE tSNE analysis was introduced in chapter 8.3.    16.3 Clustering methods Unsupervised clustering is useful in many different applications and it has been widely studied in machine learning. Some of the most popular approaches are discussed below.  16.3.1 Hierarchical clustering In hierarchical clustering, one can use either a bottom-up or a top-down approach. In the former case, each cell is initially assigned to its own cluster and pairs of clusters are subsequently merged to create a hieararchy:    Figure 16.1: Raw data      Figure 16.2: The hierarchical clustering dendrogram   With a top-down strategy, one instead starts with all observations in one cluster and then recursively split each cluster to form a hierarchy. One of the advantages of this strategy is that the method is deterministic.   16.3.2 k-means In k-means clustering, the goal is to partition N cells into k different clusters. In an iterative manner, cluster centers are assigned and each cell is assigned to its nearest cluster:    Figure 16.3: Schematic representation of the k-means clustering   Most methods for scRNA-seq analysis includes a k-means step at some point.   16.3.3 Graph-based methods Over the last two decades there has been a lot of interest in analyzing networks in various domains. One goal is to identify groups or modules of nodes in a network. Some of these methods can be applied to scRNA-seq data and one example is the method, which is based on the concept of identifying groups of tightly connected nodes.    16.4 Challenges in clustering  What is the number of clusters k? Scalability: in the last 2 years the number of cells in scRNA-seq experiments has grown by 2 orders of magnitude from ~\\(10^2\\) to ~\\(10^4\\) Tools are not user-friendly    16.5 Tools for scRNA-seq data  16.5.1 SINCERA  Based on hierarchical clustering Data is converted to z-scores before clustering Identify k by finding the first singleton cluster in the hierarchy    16.5.2 pcaReduce  Based on PCA    16.5.3 SC3  Based on PCA and spectral dimensionality reductions Utilises k-means Additionally performs the consensus clustering    16.5.4 tSNE + k-means  Based on tSNE maps Utilises k-means    16.5.5 SNN-Cliq  Based on finding the so-called “cliques” in a graph     "],
["clust-methods.html", "17 Clustering analysis 17.1 Patient dataset 17.2 SC3 17.3 pcaReduce 17.4 tSNE + kmeans 17.5 SNN-Cliq 17.6 SINCERA", " 17 Clustering analysis library(scRNA.seq.funcs) library(pcaMethods) library(pcaReduce) library(Rtsne) library(SC3) library(pheatmap) library(ggplot2) set.seed(1234567) To illustrate clustering of scRNA-seq data, we consider a dataset of hematopoietic stem cells (HSCs) collected from a patient with myeloproliferative neoplasm (MPN). It is well known that this disease is highly heterogeneous with multiple sub-clones co-existing within the same patient.  17.1 Patient dataset Traditionally, clonal heterogeneity has been assessed by genotyping sub-clones. Genotyping through Sanger sequencing of two key loci has been carried out for this patient and it has revealed the presence of 3 different sub-clones (WT, WT/Tet2 and Jak2/Tet2). Our goal is to identify clusters corresponding to the three genotypes from the scRNA-seq data. patient.data &lt;- read.table(&quot;clustering/patient.txt&quot;, sep = &quot;\\t&quot;) For convinience we have performed all quality control and normalization steps (SF + RUV) in advance. The dataset contains 51 cells and 8710 genes. Here we present several methods available for clustering of scRNA-seq data.   17.2 SC3 We first cluster this dataset using SC3: SC3::sc3(patient.data, ks = 2:5) This command will open SC3 in a web browser. Once it is opened please perform the following exercises:  Exercise 1: Explore different clustering solutions for \\(k\\) from 2 to 5. Also try to change the consensus averaging by checking and unchecking distance and transformation check boxes in the left panel of SC3. Exercise 2: Based on the genotyping, we strongly believe that \\(k =3\\) provides the best clustering. What evidence do you find for this in the clustering? How can you use the silhouette plots to motivate choosing the value of \\(k\\) that you think looks best? Exercise 3: The solution may change depending on the combination of check-boxes that was used. How similar are the different solutions, and which are the most stable clusterings? You can find out how different cells migrate between clusters using the “Cell Labels” tab panel. Exercise 4: Calculate differentially expressed genes and marker genes for the obtained clusterings. Please use \\(k=3\\) and the most stable solution, corresponding to the case when all check boxes are checked. Exercise 5: Change the marker genes threshold (the default is 0.85) in the right side panel of SC3. Does SC3 find more marker genes?    17.3 pcaReduce To run pcaReduce on the same dataset, use the following commands # use the same gene filter as in SC3 input &lt;- scRNA.seq.funcs::gene_filter(patient.data, 0.06) # log transform before the analysis input.log &lt;- log2(input + 1) # run pcaReduce 10 times creating hierarchies from 1 to 30 clusters pca.red &lt;- pcaReduce::PCAreduce(t(input.log), nbt = 10, q = 30, method = &#39;S&#39;) res &lt;- unique(scRNA.seq.funcs::merge_pcaReduce_results(pca.red, 3)) pheatmap::pheatmap(res)    Figure 17.1: Clustering solutions of pcaReduce method after running it for 10 times and selecting \\(k=3\\)   Exercise 6: Run pcaReduce for \\(k=2\\), \\(k=4\\) and \\(k=5\\). Is it easy to choose the optimal \\(k\\)? Hint: When running pcaReduce for different \\(k\\)s you do not need to rerun pcaReduce::PCAreduce function, just use already calculated pca.red object. Our solutions:    Figure 17.2: Clustering solutions of pcaReduce method after running it for 10 times and selecting \\(k=2\\).      Figure 17.3: Clustering solutions of pcaReduce method after running it for 10 times and selecting \\(k=4\\).      Figure 17.4: Clustering solutions of pcaReduce method after running it for 10 times and selecting \\(k=5\\).   Exercise 7: Compare the results between SC3 and pcaReduce. What is the main difference between the solutions provided by the two different methods?   17.4 tSNE + kmeans tSNE plots that we saw before (@ref(visual-tsne)) when used the scater package are made by using the Rtsne and ggplot2 packages. We can create a similar plots explicitly: tsne_out &lt;- Rtsne::Rtsne(t(input.log), perplexity = 10) df_to_plot &lt;- as.data.frame(tsne_out$Y) comps &lt;- colnames(df_to_plot)[1:2] ggplot2::ggplot(df_to_plot, aes_string(x = comps[1], y = comps[2])) +     geom_point() +     xlab(&quot;Dimension 1&quot;) +     ylab(&quot;Dimension 2&quot;) +     theme_bw()    Figure 17.5: tSNE map of the patient data   Note that all points on the plot above are black. This is different from what we saw before, when the cells were coloured based on the annotation. Here we do not have any annotation and all cells come from the same batch, therefore all dots are black. Now we are going to apply k-means clustering algorithm to the cloud of points on the tSNE map. Do you see 2/3/4/5 groups in the cloud? We will start with \\(k=2\\): clusts &lt;- stats::kmeans(tsne_out$Y,                         centers = 2,                         iter.max = 1e+09,                         nstart = 1000)$clust df_to_plot$clusts &lt;- factor(clusts, levels = unique(clusts)) comps &lt;- colnames(df_to_plot)[1:3] ggplot2::ggplot(df_to_plot,                 aes_string(x = comps[1], y = comps[2], color = comps[3])) +     geom_point() +     xlab(&quot;Dimension 1&quot;) +     ylab(&quot;Dimension 2&quot;) +     theme_bw()    Figure 17.6: tSNE map of the patient data with 2 colored clusters, identified by the k-means clustering algorithm   Exercise 7: Make the same plots for \\(k=3\\), \\(k=4\\) and \\(k=5\\). Exercise 8: Compare the results between SC3 and tSNE+kmeans. Can the results be improved by changing the perplexity parameter? As you may have noticed, both pcaReduce and tSNE+kmeans are stochastic and give different results every time they are run. To get a better overview of the solutions, we need to run the methods multiple times. Here we run tSNE+kmeans clustering 10 times with \\(k = 3\\) (with perplexity = 10): tsne.res &lt;- scRNA.seq.funcs::tsne_mult(input.log, 3, 10) res &lt;- unique(do.call(rbind, tsne.res)) Exercise 9: Visualize the different clustering solutions using a heatmap. Then run tSNE+kmeans algorithm with \\(k = 2\\) or \\(k = 4\\) and see how the clustering looks like in these cases.    Figure 17.7: Clustering solutions of tSNE+kmeans method after running it for 10 times and using \\(k=3\\)      Figure 17.8: Clustering solutions of tSNE+kmeans method after running it for 10 times and using \\(k=2\\)      Figure 17.9: Clustering solutions of tSNE+kmeans method after running it for 10 times and using \\(k=4\\)     17.5 SNN-Cliq To run the SNN-Cliq method: distan &lt;- &quot;euclidean&quot; par.k &lt;- 3 par.r &lt;- 0.7 par.m &lt;- 0.5 # construct a graph scRNA.seq.funcs::SNN(     data = t(input.log),     outfile = &quot;snn-cliq.txt&quot;,     k = par.k,     distance = distan ) # find clusters in the graph snn.res &lt;-      system(         paste0(             &quot;python snn-cliq/Cliq.py &quot;,              &quot;-i snn-cliq.txt &quot;,             &quot;-o res-snn-cliq.txt &quot;,             &quot;-r &quot;, par.r,             &quot; -m &quot;, par.m         ),         intern = TRUE     ) cat(paste(snn.res, collapse = &quot;\\n&quot;)) ## input file snn-cliq.txt ## find 8 quasi-cliques ## merged into 2 clusters ## unique assign done snn.res &lt;- read.table(&quot;res-snn-cliq.txt&quot;) # remove files that were created during the analysis system(&quot;rm snn-cliq.txt res-snn-cliq.txt&quot;) Exercise 10: How can you characterize the solution identified by SNN-Cliq? Run SNN-Cliq algorithm with different values of k, r, m and distance, and see how the clustering looks like in these cases.   17.6 SINCERA As mentioend in the previous chapter SINCERA is based on hierarchical clustering. One important thing to keep in mind is that it performs a gene-level z-score transformation before doing clustering: # perform gene-by-gene per-sample z-score transformation dat &lt;- apply(input, 1, function(y) scRNA.seq.funcs::z.transform.helper(y)) # hierarchical clustering dd &lt;- as.dist((1 - cor(t(dat), method = &quot;pearson&quot;))/2) hc &lt;- hclust(dd, method = &quot;average&quot;) If the number of cluster is not known SINCERA can identify k as the minimum height of the hierarchical tree that generates no more than a specified number of singleton clusters (clusters containing only 1 cell) num.singleton &lt;- 0 kk &lt;- 1 for (i in 2:dim(dat)[2]) {     clusters &lt;- cutree(hc, k = i)     clustersizes &lt;- as.data.frame(table(clusters))     singleton.clusters &lt;- which(clustersizes$Freq &lt; 2)     if (length(singleton.clusters) &lt;= num.singleton) {         kk &lt;- i     } else {         break;     } } cat(kk) ## 1 Exercise 11: Visualize the SINCERA results as a heatmap. How do the results compare to the other methods? What happens if you choose \\(k = 3\\)? Our answer:    Figure 17.10: Clustering solutions of SINCERA method using \\(k=3\\)   Exercise 12: Is using the singleton cluster criteria for finding k a good idea?   "],
["introduction-to-differential-expression-de-analysis.html", "18 Introduction to differential expression (DE) analysis 18.1 Background (bulk RNA-seq) 18.2 DE analysis for scRNA-seq 18.3 Synthetic data for scRNA-seq 18.4 Modelled expression of a single gene 18.5 Possible shapes of the Poisson-Beta distribution 18.6 Effect of sampling size on parameter estimates 18.7 Drop-out noise 18.8 Over- and under-dispersion noise", " 18 Introduction to differential expression (DE) analysis  18.1 Background (bulk RNA-seq) One of the most common types of analyses when analyzing bulk RNA-seq data is to identify differentially expressed genes. By comparing the genes that change between two conditions, e.g. mutant and wild-type or stimulated and unstimulated, it is possible to characterize the molecular mechanisms underlying the change. Several different methods, e.g. DESeq2 and edgeR, have been developed for bulk RNA-seq. Moreover, there are also extensive datasets available where the RNA-seq data has been validated using RT-qPCR. These data can be used to benchmark DE finding algorithms.   18.2 DE analysis for scRNA-seq In contrast to the bulk RNA-seq in scRNA-seq we usually do not have a defined set of experimental conditions, but instead, as was shown in the previous chapter (@ref(clust-methods)) we can identify the cell groups by using the unsupervised clustering approach. Once the groups have been identified one can find differentially expressed genes by either looking at the differencies in variance between the groups (like the Kruskal-Wallis test implemented in SC3), or by comparing gene expression between clusters in a pairwise manner. In the following chapter we will mainly consider tools developed for the comparison of the two groups of cells.   18.3 Synthetic data for scRNA-seq One advantage of working with single-cell data is that there is a reliable, analytically tractable mathematical model for the expression levels, the Poisson-Beta distribution. Importantly, the Poisson-Beta distribution has strong experimental support, and it provides a good fit to scRNA-seq data. In this module, we first discuss the Poisson-Beta distribution. We then use the model to generate synthetic data which we can use to compare different DE finding algorithms. In the final section we investigate a real scRNA-seq dataset.   18.4 Modelled expression of a single gene library(scRNA.seq.funcs) set.seed(1) For single-cell data, the analytically tractable stochastic bursting model provides a good fit. Thus, we can use it to generate realistic data. We start by generating samples from one gene: s &lt;- scRNA.seq.funcs::PoiBeta(100, 2, 3) We then plot the results as a histogram: hist(s,      freq = FALSE,      xlab = &quot;# transcripts&quot;,      main = &quot;Transcript distribution&quot;)    Figure 18.1: Distribution of read counts for a single genes across 100 cells based on the Poisson-Beta model   The probability mass function of the Poisson-Beta distribution is challenging to work with since it involves special functions. However, the mean and variance can be calculated as: \\(\\mu = k\\cdot a/(a+b)\\) \\(\\sigma^2 = k^2\\cdot a\\cdot b/((a+b+1)\\cdot(a+b)^2)\\)   18.5 Possible shapes of the Poisson-Beta distribution There are three regimes of the Poisson-Beta distribution and they are determined by the values of the parameters \\(a\\) and \\(b\\). When \\(a&lt;1\\) and \\(b&lt;1\\) we have a bimodal distribution with one mode at 0 and the other at \\(k\\), when \\(a&lt;1\\) and \\(b&gt;1\\) we have a monotonically decreasing distribution and otherwise we have a unimodal distribution with a mode at \\(ka/(a+b)\\). par(mfrow=c(3,1)) hist(scRNA.seq.funcs::PoiBeta(100, .2, .3),      freq = FALSE,      xlab = &quot;# transcripts&quot;,      col = rgb(0, 0, 1, 1/4),      breaks = seq(0, 120, 10)) hist(scRNA.seq.funcs::PoiBeta(100, .2, 3),      freq = FALSE,      xlab = &quot;# transcripts&quot;,      col = rgb(0,1,0,1/4),      breaks = seq(0, 120, 10)) hist(scRNA.seq.funcs::PoiBeta(100, 2, .3),      freq = FALSE,      xlab = &quot;# transcripts&quot;,      col = rgb(1, 0, 0, 1/4),      breaks = seq(0, 120, 10))    Figure 18.2: Different distributions of read counts for a single genes across 100 cells based on the Poisson-Beta model corresponding to different paramete sets   Exercise 1: Vary the parameters a, b and k to explore how the location and shape of the distribution changes.   18.6 Effect of sampling size on parameter estimates The difficulty in determining the parameters of the distribution also depends on the sample size. In the example below, it is not clear if the distribution is bimodal when only 10 samples are drawn. hist(scRNA.seq.funcs::PoiBeta(10, .6, 1.2, 10),      freq = FALSE,      xlab = &quot;# transcripts&quot;,      col = rgb(1, 0, 0, 1/4),      breaks = seq(0, 20, 1)) hist(scRNA.seq.funcs::PoiBeta(10, .6, 1.2, 50),      freq = FALSE,      xlab = &quot;# transcripts&quot;,      col = rgb(0, 1, 0, 1/4),      breaks = seq(0, 20, 1),      add = TRUE)    Figure 18.3: Effect of sampling size on the distribution of read counts based on the Poisson-Beta model   Exercise 2: Modify the number of samples (i.e. cells) drawn to explore how difficult it is to correctly infer the correct shape.   18.7 Drop-out noise The stochastic bursting model only captures the biological variability. In practice there will also be experimental variability. We model the noise as drop-outs, i.e. we assume that there is a small probality that each transcript is lost. For gene \\(i\\) and cell \\(j\\) it is assumed that the probability of loosing the transcript is given by \\(p_d = \\mu/(d+\\mu)\\), where \\(\\mu\\) is the mean expression level of the gene and \\(d\\) is a drop-out parameter. Thus, the probability of drop-outs monotonically decreases as the mean expression level increases. To visualize the impact of the drop-outs on a sample, we can tune the drop-out parameter: par(mfrow=c(3,1)) hist(scRNA.seq.funcs::PoiBeta(100, 2, 3, 100, 1),      freq = FALSE,      xlab = &quot;# transcripts&quot;,      col = rgb(1, 0, 0, 1/4),      ylim = c(0, .08),      xlim = c(0, 120)) hist(scRNA.seq.funcs::PoiBeta(100, 2, 3, 100, 10),      freq = FALSE,      xlab = &quot;# transcripts&quot;,      col = rgb(0, 1, 0, 1/4),      ylim = c(0, .08),      xlim = c(0, 120)) hist(scRNA.seq.funcs::PoiBeta(100, 2, 3, 100, 100),      freq = FALSE,      xlab = &quot;# transcripts&quot;,      col = rgb(0, 0, 1, 1/4),      ylim = c(0, .08),      xlim = c(0, 120))    Figure 18.4: Effect of dropouts on the distribution of read counts based on the Poisson-Beta model   Exercise 3: Explore the different parameter regimes for the same drop-out rate. Do you think that we are more sensitive to drop-outs in any specific regime?   18.8 Over- and under-dispersion noise Another example of noise is under- or over-dispersion. This can be modelled using a single parameter multiplying the parameters \\(a\\) and \\(b\\) in the Poisson-Beta distribution by a scalar \\(s\\). We can see that the mean is left unchanged while the variance is inversely proportional to \\(s\\). s &lt;- 10^(-3:3) k &lt;- 100 a &lt;- 2 b &lt;- 3 par(mfrow=c(1,1)) plot(s,      k*a*s/(a*s + b*s),      log = &quot;x&quot;,      col = &quot;red&quot;,      ylim = c(0, 50),      ylab = &quot;Moments&quot;) points(s,        k*a*s*b*s/((a*s + b*s)^2*(a*s + b*s + 1)),        col = &quot;blue&quot;)    Figure 18.5: The mean and the variance of the distribution of read counts based on the Poisson-Beta model   To illustrate the effect of the dispersion parameter on the distribution consider: par(mfrow=c(3,1)) hist(scRNA.seq.funcs::PoiBeta(100, 2, 3, 100),      freq = FALSE,      xlab = &quot;# transcripts&quot;,      col = rgb(1, 0, 0, 1/4),      ylim = c(0, .05),      xlim = c(0, 120)) hist(scRNA.seq.funcs::PoiBeta(100, 2/10, 3/10, 100),      freq = FALSE,      xlab = &quot;# transcripts&quot;,      col = rgb(0, 1, 0, 1/4),      ylim = c(0, .05),      xlim = c(0, 120)) hist(scRNA.seq.funcs::PoiBeta(100, 2*10, 3*10, 100),      freq = FALSE,      xlab = &quot;# transcripts&quot;,      col = rgb(0, 0, 1, 1/4),      ylim = c(0, .05),      xlim = c(0, 120))    Figure 18.6: Effect of dispersion on the distribution of read counts based on the Poisson-Beta model   Exercise 4: Explore what happens when you have both drop-outs and under/over-dispersion. Can the effects be deconvoluted?   "],
["de-expression-in-a-synthetic-dataset.html", "19 DE expression in a synthetic dataset 19.1 Generation of a synthetic dataset 19.2 Differential expression in scRNA-seq 19.3 Kolmogorov-Smirnov test 19.4 Performance of the KS test 19.5 Finding DE genes using DESeq2 19.6 Finding DE genes using SCDE 19.7 Comparison of the methods 19.8 Beyond changes in the mean 19.9 Further comparisons", " 19 DE expression in a synthetic dataset library(scRNA.seq.funcs) library(DESeq2) library(scde) library(ROCR) library(limma) set.seed(1)  19.1 Generation of a synthetic dataset We start by generating samples using the Poisson-Beta distribution, using 100 genes from 50 cells. To simulate the second experimental condition we select one of the three parameters for each gene and modify it by multiplying by a normally distributed random factor. nGenes &lt;- 1e2 nCells &lt;- 50 mult &lt;- 2^(rnorm(nGenes, 0, 2)) synData &lt;- scRNA.seq.funcs::GeneratePoiBetaSamples(     ks = 10^(rnorm(nGenes, 3, .5)),     as = 10^(rnorm(nGenes, -1, .5)),     bs = 10^(rnorm(nGenes, 0, .5)),     mult,     nGenes,     nCells ) g &lt;- synData$sample1 g2 &lt;- synData$sample2   19.2 Differential expression in scRNA-seq For bulk data, each gene is represented by a single value and to identify DEGs we need to identify those genes where the difference in expression between two conditions is sufficiently large. Replicates are needed for us to be able to assess the fold-change as well as its significance. For single-cell data, the situation is more complicated; instead of comparing two means we are faced with the task of comparing two probability distributions. There are many different functions available for comparing two probability distributions (e.g. Total variation distance and Kullback-Leibler divergence), and since they emphasize different features, they have different properties. To establish a ground-truth, we arbitrarily assign genes where one of the parameters has changed by more than a factor of 4 as being true positives. Remaining genes are considered not significantly changed. changedGenes &lt;- abs(log2(mult)) &gt; 2 changedGenesInds &lt;- which(changedGenes) notChangedGenesInds &lt;- which(abs(log2(mult)) &lt;= 2)   19.3 Kolmogorov-Smirnov test The types of test that are easiest to work with are non-parametric ones. The most commonly used non-parametric test is the Kolmogorov-Smirnov test (KS-test) and we can use it to compare the distributions for each gene in the two conditions. nGenes &lt;- nrow(g) pVals &lt;- rep(1, nGenes) for (i in 1:nGenes) {     res &lt;- ks.test(g[i,], g2[i,])     # Bonferroni correction     pVals[i] &lt;- res$p.value*nGenes } Using the standard p-value cut-off .05, we can find out how many genes that were called as significantly different. ksChangedGenes &lt;- which(pVals &lt; 0.05) ksNotChangedGenes &lt;- which(pVals &gt;= 0.05) cat(changedGenesInds) ## 4 11 14 15 24 28 31 35 39 54 55 56 58 61 67 68 70 75 83 84 87 92 93 95 97 99 cat(ksChangedGenes) ## 13 28 31 35 40 55 56 61 67 84 87 97 cat(intersect(changedGenesInds, ksChangedGenes)) ## 28 31 35 55 56 61 67 84 87 97   19.4 Performance of the KS test The genes identified by the KS-test differs substantially from the ground truth. Instead of considering the absolute number of identified genes, it is often more informative to consider False positive rate (FPR) and the True positive rate (TPR). The False positive rate is defined as FPR = FP/(FP + TP) and the True positive rate as TPR = TP/(TP + FN), where FP is the number of false positives, TN the number of true negatives, TP the number of true negatives and FN the number of false negatives. tp &lt;- length(intersect(changedGenesInds, ksChangedGenes)) fn &lt;- length(intersect(changedGenesInds, which(pVals &gt;= .05))) fp &lt;- length(intersect(notChangedGenesInds, ksChangedGenes)) tn &lt;- length(intersect(notChangedGenesInds, which(pVals &gt;= .05))) tpr &lt;- tp/(tp + fn) fpr &lt;- fp/(fp + tn) cat(c(tpr, fpr)) ## 0.3846154 0.02702703 As you can see, the p-value cut-off .05 results in a low TPR and a high FPR. That is, the test has failed to identify many of the genes that were truly changed and many of the changed genes were not detected. Clearly, there is a trade-off between TPR and FPR. If one is willing to accept a higher FPR, then one will be able to achieve a higher TPR. The relationship between FPR and TPR is typically shown as a receiver-operator-characteristic (ROC) curve. To generate and plot the ROC curve, we need to change the p-value cut-off. To facilitate the plotting, we use the package “ROCR” pred &lt;- ROCR::prediction(pVals, as.numeric(abs(log2(mult)) &lt;= 2)) perf &lt;- ROCR::performance(pred, &quot;tpr&quot;, &quot;fpr&quot;) ROCR::plot(perf)      Figure 19.1: Different distributions of read counts for a single genes across 50 cells based on the Poisson-Beta model corresponding to different paramete sets   Often we are interested in comparing several ROC curves. To carry out such a comparison, we need to summarize the entire curve using only one scalar value. This can be achieved by calculating the area under the ROC curve (AUROC). Since an ROC curve has to stay above the diagonal (why?) the AUROC will be between .5 and 1. aucObj &lt;- ROCR::performance(pred, &quot;auc&quot;) aucObj@y.values[[1]] ## [1] 0.7837838 Exercise: Compare the AUC values when you change some of the parameters in the analysis, e.g. number of cells, number of genes, threshold for considering a gene differentially expressed, distribution of parameter values, distribution of fold-changes. What factors make it easy or hard to identify differentially expressed genes?   19.5 Finding DE genes using DESeq2 One could still apply bulk DE methods to scRNA-seq data. One of the most popular methods for differential expression analysis for bulk RNA-Seq data is DESeq2. Let’s try it out on our synthetic dataset: cnts &lt;- cbind(g, g2) cond &lt;- factor(     c(         rep(&quot;A&quot;, ncol(g)),         rep(&quot;B&quot;, ncol(g2))     ) ) # object construction, add a pseudo-count of 1 to make DESeq work dds &lt;- DESeq2::DESeqDataSetFromMatrix(     cnts + 1,      DataFrame(cond),      ~ cond) dds &lt;- DESeq2::DESeq(dds) resDESeq &lt;- results(dds) Check the performance of DESeq2: pValsDESeq &lt;- resDESeq$padj predDESeq &lt;- prediction(pValsDESeq, as.numeric(abs(log2(mult)) &lt;= 2)) perfDESeq &lt;- performance(predDESeq, &quot;tpr&quot;, &quot;fpr&quot;) ROCR::plot(perfDESeq)      Figure 19.2: Different distributions of read counts for a single genes across 50 cells based on the Poisson-Beta model corresponding to different paramete sets   aucObjDESeq &lt;- performance(predDESeq, &quot;auc&quot;) aucObjDESeq@y.values[[1]] ## [1] 0.8503119 Exercise: Based on the AUC-value, does DESeq or the KS-test seem more accurate? Can you find a parameter regime where the ranking is changed?   19.6 Finding DE genes using SCDE There are yet much fewer methods available for scRNA-seq data than for bulk data, but one popular method is SCDE. We can use it on the synthetic data: cnts &lt;- cbind(g, g2) cnts &lt;- apply(     cnts,     2,      function(x) {         storage.mode(x) &lt;- &#39;integer&#39;         return(x)     } ) cond &lt;- factor(     c(         rep(&quot;A&quot;, ncol(g)),         rep(&quot;B&quot;, ncol(g2))     ) ) names(cond) &lt;- 1:length(cnts[1, ]) colnames(cnts) &lt;- 1:length(cnts[1, ])  o.ifm &lt;- scde::scde.error.models(     counts = cnts,     groups = cond,     n.cores = 1,     threshold.segmentation = TRUE,     save.crossfit.plots = FALSE,     save.model.plots = FALSE,     verbose = 0,     min.size.entries = 20 ) priors &lt;- scde::scde.expression.prior(     models = o.ifm,     counts = cnts,     length.out = 400,     show.plot = FALSE) resSCDE1 &lt;- scde::scde.expression.difference(     o.ifm,     cnts,     priors,     groups = cond,     n.randomizations = 100,     n.cores = 1,     verbose = 0) pValsSCDE1 &lt;- pnorm(resSCDE1$cZ, lower.tail = FALSE)  # Need to run the other way as well  cnts2 &lt;- cbind(g2, g) cnts2 &lt;- apply(     cnts2,      2,      function(x) {         storage.mode(x) &lt;- &#39;integer&#39;         return(x)     } ) names(cond) &lt;- 1:length(cnts2[1, ]) colnames(cnts2) &lt;- 1:length(cnts2[1, ])  o.ifm &lt;- scde::scde.error.models(     counts = cnts2,     groups = cond,     n.cores = 1,     threshold.segmentation = TRUE,     save.crossfit.plots = FALSE,     save.model.plots = FALSE,     verbose = 0,     min.size.entries = 20 ) priors &lt;- scde::scde.expression.prior(     models = o.ifm,     counts = cnts2,     length.out = 400,     show.plot = FALSE ) resSCDE2 &lt;- scde::scde.expression.difference(     o.ifm,     cnts2,     priors,     groups = cond,     n.randomizations = 100,     n.cores = 1,     verbose = 0 ) pValsSCDE2 &lt;- pnorm(resSCDE2$cZ, lower.tail = FALSE)  As you can see, SCDE is different from the KS-test and DESeq2 since it only searches for changes in one direction. Thus, if we want to find both upregulated and downregulated genes, we must run the software twice and then combine the results as we have done above. Exercise: Merge the results from the two runs and produce a single list of p-values and (absolute) fold-changes for all genes. Based on these results, calculate an AUROC value and compare to the other methods. Hint: Keep in mind that we are now doing two tests for each gene. Our answer:  ## [1] 0.8607069   19.7 Comparison of the methods From the above analyses it is clear that none of the three methods (KS, DESeq2 and SCDE) is able to reliably find the majority of the DE genes. A popular strategy in this situation is to combine two or more methods, in the hope that genes that were identified by more than method are more likely to be true positives. par(mfrow = c(1, 1)) limma::vennDiagram(     vennCounts(         cbind(             1 - changedGenes,             pValsDESeq &lt; .05,             pValsSCDE &lt; .05,             pVals &lt; .05         )     ),     names = c(&quot;Ground truth&quot;, &quot;DESeq2&quot;, &quot;SCDE&quot;, &quot;KS-test&quot;),     circle.col = c(&quot;magenta&quot;, &quot;blue&quot;, &quot;green&quot;, &quot;red&quot;))  allChangedInds &lt;- intersect(     which(pValsDESeq &lt; .05),     intersect(which(pValsSCDE &lt; .05),               which(pVals &lt; .05)     ) ) tpAll &lt;- length(intersect(changedGenesInds, allChangedInds)) fnAll &lt;- length(intersect(changedGenesInds, setdiff(1:1e3, allChangedInds))) fpAll &lt;- length(intersect(notChangedGenesInds, allChangedInds)) tnAll &lt;- length(intersect(notChangedGenesInds, setdiff(1:1e3, allChangedInds))) tprAll &lt;- tpAll / (tpAll + fnAll) fprAll &lt;- fpAll / (fpAll + tnAll) cat(c(tprAll, fprAll)) ## 0.3846154 0.01351351 The more stringent approach results in a lower FPR at the cost of a lower TPR. Exercise: Calculate the TPR and FPR for the case when we require two out of three methods to agree.   19.8 Beyond changes in the mean In the realm of single-cell analyses, differential expression is no longer restricted to changes in the mean. As we saw in the previous chapter, it is possible to change the shape of the distribution without changing its mean. Exercise: Repeat the analysis above, but this time only change the variance, but not the mean. To generate the synthetic data, use the following command: nGenes &lt;- 1e2 nCells &lt;- 50 mult &lt;- 2^(rnorm(nGenes, 0, 2)) synData &lt;- scRNA.seq.funcs::GeneratePoiBetaSamples(     ks = 10^(rnorm(nGenes, 3, .5)),     as = 10^(rnorm(nGenes, -1, .5)),     bs = 10^(rnorm(nGenes, 0, .5)),     mult,     nGenes,     nCells,     meanFixed = TRUE ) g &lt;- synData$sample1 g2 &lt;- synData$sample2 Our answer:  ## [1] 0.8123021  ## [1] 0.475142  ## [1] 0.4312528 Which method performs the best? Why do some methods perform differently for this scenario? What are the properties of the genes that are identified as DE?   19.9 Further comparisons To get more confidence in saying which method is better, the methods can be compared multiple times.   "],
["de-expression-in-a-real-dataset.html", "20 DE expression in a real dataset 20.1 Introduction 20.2 KS-test 20.3 DESeq2 20.4 SCDE 20.5 Comparison of the methods", " 20 DE expression in a real dataset library(scRNA.seq.funcs) library(DESeq2) library(scde) library(ROCR) library(limma) set.seed(1)  20.1 Introduction The main advantage of using synthetic data is that we have full control over all aspects of the data, and this facilitates the interpretation of the results. However, the transcriptional bursting model is unable to capture the full complexity of a real scRNA-seq dataset. Next, we are going to analyze the difference between the transcriptomes of the 2-cell and the 4-cell state of a mouse embryo as described by Biase et al. For our purposes you need to download the biase into the biase folder in your working directory. We can then look at the data: biase &lt;- as.matrix(     read.table(         &quot;biase/biase_et_al_2cell_4cell_fpkm.tsv&quot;     ) ) # keep those genes that are expressed in at least 6 cells biase &lt;- biase[rowSums(biase &gt; 0) &gt; 5, ] pheatmap::pheatmap(     log2(biase + 1),     scale = &quot;column&quot;,     cutree_cols = 2,     kmeans_k = 100,     show_rownames = FALSE )  As you can see, the cells cluster well by their developmental stage. We can now use the same methods as before to obtain a list of differentially expressed genes. Because SCDE is very slow here we will only use a subset of genes. You should not do that with your real dataset, though. Here we do it just for demostration purposes: biase &lt;- biase[sample(1:nrow(biase), 500), ]   20.2 KS-test pVals &lt;- rep(1, nrow(biase)) for (i in 1:nrow(biase)) {     res &lt;- ks.test(         biase[i, 1:20],         biase[i , 21:40]     )     # Bonferroni correction     pVals[i] &lt;- res$p.value * nrow(biase) }   20.3 DESeq2 Because the number of genes now is 500, which is about 100 times more than the number of genes we used for the synthetic dataset, this calculation will take some time. You do not need to run it during the course, instead just check the results below. cond &lt;- factor(     c(         rep(&quot;cell2&quot;, 20),         rep(&quot;cell4&quot;, 20)     ) ) dds &lt;- DESeq2::DESeqDataSetFromMatrix(     round(biase) + 1,     colData = DataFrame(cond),     design = ~ cond ) dds &lt;- DESeq2::DESeq(dds) resDESeq &lt;- DESeq2::results(dds) pValsDESeq &lt;- resDESeq$padj   20.4 SCDE Because the number of genes now is 500, which is about 100 times more than the number of genes we used for the synthetic dataset, this calculation will take quite a lot of time. You do not need to run it during the course, instead just check the results below. cnts &lt;- apply(     biase,     2,     function(x) {         storage.mode(x) &lt;- &#39;integer&#39;         return(x)     } ) names(cond) &lt;- 1:length(cnts[1, ]) colnames(cnts) &lt;- 1:length(cnts[1, ])  o.ifm &lt;- scde::scde.error.models(     counts = cnts,     groups = cond,     n.cores = 1,     threshold.segmentation = TRUE,     save.crossfit.plots = FALSE,     save.model.plots = FALSE,     verbose = 0,     min.size.entries = 2 ) priors &lt;- scde::scde.expression.prior(     models = o.ifm,     counts = cnts,     length.out = 400,     show.plot = FALSE ) resSCDE1 &lt;- scde::scde.expression.difference(     o.ifm,     cnts,     priors,     groups = cond,     n.randomizations = 100,     n.cores = 1,     verbose = 0 ) pValsSCDE1 &lt;- pnorm(resSCDE1$cZ, lower.tail = F)  cnts2 &lt;- apply(     biase[ , c(21:40, 1:20)],     2,     function(x) {         storage.mode(x) &lt;- &#39;integer&#39;         return(x)     } ) names(cond) &lt;- 1:length(cnts2[1, ]) colnames(cnts2) &lt;- 1:length(cnts2[1, ])  o.ifm &lt;- scde::scde.error.models(     counts = cnts2,     groups = cond,     n.cores = 1,     threshold.segmentation = TRUE,     save.crossfit.plots = FALSE,     save.model.plots = FALSE,     verbose = 0,     min.size.entries = 2 ) priors &lt;- scde::scde.expression.prior(     models = o.ifm,     counts = cnts2,     length.out = 400,     show.plot = F ) resSCDE2 &lt;- scde::scde.expression.difference(     o.ifm,     cnts2,     priors,     groups = cond,     n.randomizations = 100,     n.cores = 1,     verbose = 0 ) pValsSCDE2 &lt;- pnorm(resSCDE2$cZ, lower.tail = F)   pValsSCDECombined &lt;- rbind(pValsSCDE1, pValsSCDE2) minSCDEInds &lt;- apply(pValsSCDECombined, 2, which.min) pValsSCDE &lt;- apply(pValsSCDECombined*2, 2, min) #Bonferroni correction   20.5 Comparison of the methods vennDiagram(     vennCounts(         cbind(             pVals &lt; 0.05,             pValsDESeq &lt; 0.05,             pValsSCDE &lt; 0.05         )     ),     names = c(&quot;KS-test&quot;, &quot;DESeq2&quot;, &quot;SCDE&quot;),     circle.col = c(&quot;red&quot;, &quot;blue&quot;, &quot;green&quot;) )  Exercise: How does this Venn diagram correspond to what you would expect based on the synthetic data?   "],
["references.html", "21 References", " 21 References    Handley, Ava, Tamás Schauer, Andreas G Ladurner, and Carla E Margulies. 2015. “Designing Cell-Type-Specific Genome-Wide Experiments.” Mol. Cell 58 (4): 621–31.   Hashimshony, Tamar, Florian Wagner, Noa Sher, and Itai Yanai. 2012. “CEL-Seq: Single-Cell RNA-Seq by Multiplexed Linear Amplification.” Cell Rep. 2 (3): 666–73.   Jiang, Lichun, Felix Schlesinger, Carrie A Davis, Yu Zhang, Renhua Li, Marc Salit, Thomas R Gingeras, and Brian Oliver. 2011. “Synthetic Spike-in Standards for RNA-seq Experiments.” Genome Res. 21 (9): 1543–51.   Kharchenko, Peter V, Lev Silberstein, and David T Scadden. 2014. “Bayesian Approach to Single-Cell Differential Expression Analysis.” Nat. Methods 11 (7): 740–42.   Kivioja, Teemu, Anna Vähärautio, Kasper Karlsson, Martin Bonke, Martin Enge, Sten Linnarsson, and Jussi Taipale. 2012. “Counting Absolute Numbers of Molecules Using Unique Molecular Identifiers.” Nat. Methods 9 (1): 72–74.   Kolodziejczyk, Aleksandra A, Jong Kyoung Kim, Valentine Svensson, John C Marioni, and Sarah A Teichmann. 2015. “The Technology and Biology of Single-Cell RNA Sequencing.” Mol. Cell 58 (4): 610–20.   Macosko, Evan Z, Anindita Basu, Rahul Satija, James Nemesh, Karthik Shekhar, Melissa Goldman, Itay Tirosh, et al. 2015. “Highly Parallel Genome-Wide Expression Profiling of Individual Cells Using Nanoliter Droplets.” Cell 161 (5): 1202–14.   Picelli, Simone, Åsa K Björklund, Omid R Faridani, Sven Sagasser, Gösta Winberg, and Rickard Sandberg. 2013. “Smart-Seq2 for Sensitive Full-Length Transcriptome Profiling in Single Cells.” Nat. Methods 10 (11): 1096–8.   Saliba, Antoine-Emmanuel, Alexander J Westermann, Stanislaw A Gorski, and Jörg Vogel. 2014. “Single-Cell RNA-seq: Advances and Future Challenges.” Nucleic Acids Res. 42 (14): 8845–60.   Stegle, Oliver, Sarah A Teichmann, and John C Marioni. 2015. “Computational and Analytical Challenges in Single-Cell Transcriptomics.” Nat. Rev. Genet. 16 (3): 133–45.   Tang, Fuchou, Catalin Barbacioru, Yangzhou Wang, Ellen Nordman, Clarence Lee, Nanlan Xu, Xiaohui Wang, et al. 2009. “mRNA-Seq Whole-Transcriptome Analysis of a Single Cell.” Nat. Methods 6 (5): 377–82.   "]
]
